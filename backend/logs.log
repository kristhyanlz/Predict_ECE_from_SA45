2024-11-04 11:26:29,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:26:29,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:26:29,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:26:29,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:26:29,858:INFO:PyCaret ClassificationExperiment
2024-11-04 11:26:29,858:INFO:Logging name: clf-default-name
2024-11-04 11:26:29,858:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:26:29,858:INFO:version 3.3.2
2024-11-04 11:26:29,858:INFO:Initializing setup()
2024-11-04 11:26:29,858:INFO:self.USI: 9003
2024-11-04 11:26:29,858:INFO:self._variable_keys: {'log_plots_param', 'idx', 'memory', 'X', 'n_jobs_param', 'pipeline', 'seed', 'html_param', 'gpu_n_jobs_param', 'USI', 'exp_id', 'is_multiclass', 'data', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'logging_param', '_available_plots', 'X_test', 'y', 'fold_generator', 'target_param', 'y_test', 'fold_groups_param', 'fix_imbalance', '_ml_usecase', 'y_train', 'X_train'}
2024-11-04 11:26:29,858:INFO:Checking environment
2024-11-04 11:26:29,858:INFO:python_version: 3.11.2
2024-11-04 11:26:29,858:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:26:29,859:INFO:machine: x86_64
2024-11-04 11:26:29,860:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:26:29,860:INFO:Memory: svmem(total=16721211392, available=10216644608, percent=38.9, used=6040096768, free=4301643776, active=1762340864, inactive=9641615360, buffers=306909184, cached=6072561664, shared=115830784, slab=524374016)
2024-11-04 11:26:29,860:INFO:Physical Core: 4
2024-11-04 11:26:29,860:INFO:Logical Core: 8
2024-11-04 11:26:29,860:INFO:Checking libraries
2024-11-04 11:26:29,860:INFO:System:
2024-11-04 11:26:29,860:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:26:29,860:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:26:29,861:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:26:29,861:INFO:PyCaret required dependencies:
2024-11-04 11:26:29,875:INFO:                 pip: 23.0.1
2024-11-04 11:26:29,875:INFO:          setuptools: 66.1.1
2024-11-04 11:26:29,875:INFO:             pycaret: 3.3.2
2024-11-04 11:26:29,875:INFO:             IPython: 8.29.0
2024-11-04 11:26:29,875:INFO:          ipywidgets: 8.1.5
2024-11-04 11:26:29,875:INFO:                tqdm: 4.66.6
2024-11-04 11:26:29,875:INFO:               numpy: 1.26.4
2024-11-04 11:26:29,875:INFO:              pandas: 2.1.4
2024-11-04 11:26:29,875:INFO:              jinja2: 3.1.4
2024-11-04 11:26:29,875:INFO:               scipy: 1.11.4
2024-11-04 11:26:29,875:INFO:              joblib: 1.3.2
2024-11-04 11:26:29,875:INFO:             sklearn: 1.4.2
2024-11-04 11:26:29,875:INFO:                pyod: 2.0.2
2024-11-04 11:26:29,875:INFO:            imblearn: 0.12.4
2024-11-04 11:26:29,875:INFO:   category_encoders: 2.6.4
2024-11-04 11:26:29,875:INFO:            lightgbm: 4.5.0
2024-11-04 11:26:29,875:INFO:               numba: 0.60.0
2024-11-04 11:26:29,875:INFO:            requests: 2.32.3
2024-11-04 11:26:29,875:INFO:          matplotlib: 3.7.5
2024-11-04 11:26:29,875:INFO:          scikitplot: 0.3.7
2024-11-04 11:26:29,876:INFO:         yellowbrick: 1.5
2024-11-04 11:26:29,876:INFO:              plotly: 5.24.1
2024-11-04 11:26:29,876:INFO:    plotly-resampler: Not installed
2024-11-04 11:26:29,876:INFO:             kaleido: 0.2.1
2024-11-04 11:26:29,876:INFO:           schemdraw: 0.15
2024-11-04 11:26:29,876:INFO:         statsmodels: 0.14.4
2024-11-04 11:26:29,876:INFO:              sktime: 0.26.0
2024-11-04 11:26:29,876:INFO:               tbats: 1.1.3
2024-11-04 11:26:29,876:INFO:            pmdarima: 2.0.4
2024-11-04 11:26:29,876:INFO:              psutil: 6.1.0
2024-11-04 11:26:29,876:INFO:          markupsafe: 3.0.2
2024-11-04 11:26:29,876:INFO:             pickle5: Not installed
2024-11-04 11:26:29,876:INFO:         cloudpickle: 3.1.0
2024-11-04 11:26:29,876:INFO:         deprecation: 2.1.0
2024-11-04 11:26:29,876:INFO:              xxhash: 3.5.0
2024-11-04 11:26:29,876:INFO:           wurlitzer: 3.1.1
2024-11-04 11:26:29,876:INFO:PyCaret optional dependencies:
2024-11-04 11:26:29,889:INFO:                shap: Not installed
2024-11-04 11:26:29,889:INFO:           interpret: Not installed
2024-11-04 11:26:29,889:INFO:                umap: Not installed
2024-11-04 11:26:29,889:INFO:     ydata_profiling: Not installed
2024-11-04 11:26:29,889:INFO:  explainerdashboard: Not installed
2024-11-04 11:26:29,889:INFO:             autoviz: Not installed
2024-11-04 11:26:29,889:INFO:           fairlearn: Not installed
2024-11-04 11:26:29,890:INFO:          deepchecks: Not installed
2024-11-04 11:26:29,890:INFO:             xgboost: Not installed
2024-11-04 11:26:29,890:INFO:            catboost: Not installed
2024-11-04 11:26:29,890:INFO:              kmodes: Not installed
2024-11-04 11:26:29,890:INFO:             mlxtend: Not installed
2024-11-04 11:26:29,890:INFO:       statsforecast: Not installed
2024-11-04 11:26:29,890:INFO:        tune_sklearn: Not installed
2024-11-04 11:26:29,890:INFO:                 ray: Not installed
2024-11-04 11:26:29,890:INFO:            hyperopt: Not installed
2024-11-04 11:26:29,890:INFO:              optuna: Not installed
2024-11-04 11:26:29,890:INFO:               skopt: Not installed
2024-11-04 11:26:29,890:INFO:              mlflow: Not installed
2024-11-04 11:26:29,890:INFO:              gradio: Not installed
2024-11-04 11:26:29,890:INFO:             fastapi: Not installed
2024-11-04 11:26:29,890:INFO:             uvicorn: Not installed
2024-11-04 11:26:29,890:INFO:              m2cgen: Not installed
2024-11-04 11:26:29,890:INFO:           evidently: Not installed
2024-11-04 11:26:29,890:INFO:               fugue: Not installed
2024-11-04 11:26:29,890:INFO:           streamlit: Not installed
2024-11-04 11:26:29,890:INFO:             prophet: Not installed
2024-11-04 11:26:29,890:INFO:None
2024-11-04 11:26:29,890:INFO:Set up data.
2024-11-04 11:26:29,895:INFO:Set up folding strategy.
2024-11-04 11:26:29,895:INFO:Set up train/test split.
2024-11-04 11:26:29,900:INFO:Set up index.
2024-11-04 11:26:29,900:INFO:Assigning column types.
2024-11-04 11:26:29,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:26:29,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:26:29,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:29,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:29,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:29,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:26:29,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,015:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:26:30,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,097:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,116:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:26:30,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,216:INFO:Preparing preprocessing pipeline...
2024-11-04 11:26:30,217:INFO:Set up simple imputation.
2024-11-04 11:26:30,219:INFO:Set up encoding of categorical features.
2024-11-04 11:26:30,219:INFO:Set up column name cleaning.
2024-11-04 11:26:30,320:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:26:30,325:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:26:30,325:INFO:Creating final display dataframe.
2024-11-04 11:26:30,541:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                 4
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              9003
2024-11-04 11:26:30,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,693:INFO:setup() successfully completed in 0.84s...............
2024-11-04 11:26:30,694:INFO:PyCaret ClassificationExperiment
2024-11-04 11:26:30,694:INFO:Logging name: clf-default-name
2024-11-04 11:26:30,694:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:26:30,694:INFO:version 3.3.2
2024-11-04 11:26:30,694:INFO:Initializing setup()
2024-11-04 11:26:30,694:INFO:self.USI: 271a
2024-11-04 11:26:30,694:INFO:self._variable_keys: {'log_plots_param', 'idx', 'memory', 'X', 'n_jobs_param', 'pipeline', 'seed', 'html_param', 'gpu_n_jobs_param', 'USI', 'exp_id', 'is_multiclass', 'data', 'fold_shuffle_param', 'exp_name_log', 'gpu_param', 'logging_param', '_available_plots', 'X_test', 'y', 'fold_generator', 'target_param', 'y_test', 'fold_groups_param', 'fix_imbalance', '_ml_usecase', 'y_train', 'X_train'}
2024-11-04 11:26:30,694:INFO:Checking environment
2024-11-04 11:26:30,694:INFO:python_version: 3.11.2
2024-11-04 11:26:30,694:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:26:30,694:INFO:machine: x86_64
2024-11-04 11:26:30,694:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:26:30,694:INFO:Memory: svmem(total=16721211392, available=10236317696, percent=38.8, used=6018195456, free=4321136640, active=1762361344, inactive=9621966848, buffers=306909184, cached=6074970112, shared=118059008, slab=524435456)
2024-11-04 11:26:30,695:INFO:Physical Core: 4
2024-11-04 11:26:30,695:INFO:Logical Core: 8
2024-11-04 11:26:30,695:INFO:Checking libraries
2024-11-04 11:26:30,695:INFO:System:
2024-11-04 11:26:30,695:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:26:30,695:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:26:30,695:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:26:30,695:INFO:PyCaret required dependencies:
2024-11-04 11:26:30,695:INFO:                 pip: 23.0.1
2024-11-04 11:26:30,695:INFO:          setuptools: 66.1.1
2024-11-04 11:26:30,695:INFO:             pycaret: 3.3.2
2024-11-04 11:26:30,695:INFO:             IPython: 8.29.0
2024-11-04 11:26:30,695:INFO:          ipywidgets: 8.1.5
2024-11-04 11:26:30,695:INFO:                tqdm: 4.66.6
2024-11-04 11:26:30,695:INFO:               numpy: 1.26.4
2024-11-04 11:26:30,695:INFO:              pandas: 2.1.4
2024-11-04 11:26:30,695:INFO:              jinja2: 3.1.4
2024-11-04 11:26:30,695:INFO:               scipy: 1.11.4
2024-11-04 11:26:30,695:INFO:              joblib: 1.3.2
2024-11-04 11:26:30,695:INFO:             sklearn: 1.4.2
2024-11-04 11:26:30,695:INFO:                pyod: 2.0.2
2024-11-04 11:26:30,695:INFO:            imblearn: 0.12.4
2024-11-04 11:26:30,695:INFO:   category_encoders: 2.6.4
2024-11-04 11:26:30,696:INFO:            lightgbm: 4.5.0
2024-11-04 11:26:30,696:INFO:               numba: 0.60.0
2024-11-04 11:26:30,696:INFO:            requests: 2.32.3
2024-11-04 11:26:30,696:INFO:          matplotlib: 3.7.5
2024-11-04 11:26:30,696:INFO:          scikitplot: 0.3.7
2024-11-04 11:26:30,696:INFO:         yellowbrick: 1.5
2024-11-04 11:26:30,696:INFO:              plotly: 5.24.1
2024-11-04 11:26:30,696:INFO:    plotly-resampler: Not installed
2024-11-04 11:26:30,696:INFO:             kaleido: 0.2.1
2024-11-04 11:26:30,696:INFO:           schemdraw: 0.15
2024-11-04 11:26:30,696:INFO:         statsmodels: 0.14.4
2024-11-04 11:26:30,696:INFO:              sktime: 0.26.0
2024-11-04 11:26:30,696:INFO:               tbats: 1.1.3
2024-11-04 11:26:30,696:INFO:            pmdarima: 2.0.4
2024-11-04 11:26:30,696:INFO:              psutil: 6.1.0
2024-11-04 11:26:30,696:INFO:          markupsafe: 3.0.2
2024-11-04 11:26:30,696:INFO:             pickle5: Not installed
2024-11-04 11:26:30,696:INFO:         cloudpickle: 3.1.0
2024-11-04 11:26:30,696:INFO:         deprecation: 2.1.0
2024-11-04 11:26:30,696:INFO:              xxhash: 3.5.0
2024-11-04 11:26:30,696:INFO:           wurlitzer: 3.1.1
2024-11-04 11:26:30,696:INFO:PyCaret optional dependencies:
2024-11-04 11:26:30,696:INFO:                shap: Not installed
2024-11-04 11:26:30,696:INFO:           interpret: Not installed
2024-11-04 11:26:30,696:INFO:                umap: Not installed
2024-11-04 11:26:30,696:INFO:     ydata_profiling: Not installed
2024-11-04 11:26:30,696:INFO:  explainerdashboard: Not installed
2024-11-04 11:26:30,696:INFO:             autoviz: Not installed
2024-11-04 11:26:30,696:INFO:           fairlearn: Not installed
2024-11-04 11:26:30,696:INFO:          deepchecks: Not installed
2024-11-04 11:26:30,696:INFO:             xgboost: Not installed
2024-11-04 11:26:30,696:INFO:            catboost: Not installed
2024-11-04 11:26:30,697:INFO:              kmodes: Not installed
2024-11-04 11:26:30,697:INFO:             mlxtend: Not installed
2024-11-04 11:26:30,697:INFO:       statsforecast: Not installed
2024-11-04 11:26:30,697:INFO:        tune_sklearn: Not installed
2024-11-04 11:26:30,697:INFO:                 ray: Not installed
2024-11-04 11:26:30,697:INFO:            hyperopt: Not installed
2024-11-04 11:26:30,697:INFO:              optuna: Not installed
2024-11-04 11:26:30,697:INFO:               skopt: Not installed
2024-11-04 11:26:30,697:INFO:              mlflow: Not installed
2024-11-04 11:26:30,697:INFO:              gradio: Not installed
2024-11-04 11:26:30,697:INFO:             fastapi: Not installed
2024-11-04 11:26:30,697:INFO:             uvicorn: Not installed
2024-11-04 11:26:30,697:INFO:              m2cgen: Not installed
2024-11-04 11:26:30,697:INFO:           evidently: Not installed
2024-11-04 11:26:30,697:INFO:               fugue: Not installed
2024-11-04 11:26:30,697:INFO:           streamlit: Not installed
2024-11-04 11:26:30,697:INFO:             prophet: Not installed
2024-11-04 11:26:30,697:INFO:None
2024-11-04 11:26:30,697:INFO:Set up data.
2024-11-04 11:26:30,702:INFO:Set up folding strategy.
2024-11-04 11:26:30,702:INFO:Set up train/test split.
2024-11-04 11:26:30,705:INFO:Set up index.
2024-11-04 11:26:30,705:INFO:Assigning column types.
2024-11-04 11:26:30,707:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:26:30,737:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,806:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:26:30,836:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:26:30,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,905:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:26:30,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:30,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,002:INFO:Preparing preprocessing pipeline...
2024-11-04 11:26:31,003:INFO:Set up simple imputation.
2024-11-04 11:26:31,005:INFO:Set up encoding of categorical features.
2024-11-04 11:26:31,005:INFO:Set up column name cleaning.
2024-11-04 11:26:31,100:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:26:31,104:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:26:31,104:INFO:Creating final display dataframe.
2024-11-04 11:26:31,332:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              271a
2024-11-04 11:26:31,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:26:31,453:INFO:setup() successfully completed in 0.76s...............
2024-11-04 11:26:31,453:INFO:Initializing compare_models()
2024-11-04 11:26:31,453:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-04 11:26:31,453:INFO:Checking exceptions
2024-11-04 11:26:31,455:INFO:Preparing display monitor
2024-11-04 11:26:31,457:INFO:Initializing Logistic Regression
2024-11-04 11:26:31,457:INFO:Total runtime is 1.1920928955078125e-06 minutes
2024-11-04 11:26:31,458:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:31,458:INFO:Initializing create_model()
2024-11-04 11:26:31,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:31,458:INFO:Checking exceptions
2024-11-04 11:26:31,458:INFO:Importing libraries
2024-11-04 11:26:31,458:INFO:Copying training dataset
2024-11-04 11:26:31,461:INFO:Defining folds
2024-11-04 11:26:31,461:INFO:Declaring metric variables
2024-11-04 11:26:31,461:INFO:Importing untrained model
2024-11-04 11:26:31,461:INFO:Logistic Regression Imported successfully
2024-11-04 11:26:31,461:INFO:Starting cross validation
2024-11-04 11:26:31,463:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:33,134:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:33,177:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:33,324:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:33,348:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:33,360:INFO:Calculating mean and std
2024-11-04 11:26:33,361:INFO:Creating metrics dataframe
2024-11-04 11:26:33,365:INFO:Uploading results into container
2024-11-04 11:26:33,366:INFO:Uploading model into container now
2024-11-04 11:26:33,366:INFO:_master_model_container: 1
2024-11-04 11:26:33,367:INFO:_display_container: 2
2024-11-04 11:26:33,367:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-04 11:26:33,368:INFO:create_model() successfully completed......................................
2024-11-04 11:26:33,471:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:33,471:INFO:Creating metrics dataframe
2024-11-04 11:26:33,473:INFO:Initializing K Neighbors Classifier
2024-11-04 11:26:33,473:INFO:Total runtime is 0.03360196352005005 minutes
2024-11-04 11:26:33,474:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:33,474:INFO:Initializing create_model()
2024-11-04 11:26:33,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:33,474:INFO:Checking exceptions
2024-11-04 11:26:33,474:INFO:Importing libraries
2024-11-04 11:26:33,474:INFO:Copying training dataset
2024-11-04 11:26:33,477:INFO:Defining folds
2024-11-04 11:26:33,477:INFO:Declaring metric variables
2024-11-04 11:26:33,477:INFO:Importing untrained model
2024-11-04 11:26:33,477:INFO:K Neighbors Classifier Imported successfully
2024-11-04 11:26:33,477:INFO:Starting cross validation
2024-11-04 11:26:33,479:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:35,152:INFO:Calculating mean and std
2024-11-04 11:26:35,153:INFO:Creating metrics dataframe
2024-11-04 11:26:35,155:INFO:Uploading results into container
2024-11-04 11:26:35,155:INFO:Uploading model into container now
2024-11-04 11:26:35,156:INFO:_master_model_container: 2
2024-11-04 11:26:35,156:INFO:_display_container: 2
2024-11-04 11:26:35,156:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-04 11:26:35,156:INFO:create_model() successfully completed......................................
2024-11-04 11:26:35,257:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:35,258:INFO:Creating metrics dataframe
2024-11-04 11:26:35,260:INFO:Initializing Naive Bayes
2024-11-04 11:26:35,261:INFO:Total runtime is 0.06338812112808227 minutes
2024-11-04 11:26:35,261:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:35,261:INFO:Initializing create_model()
2024-11-04 11:26:35,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:35,261:INFO:Checking exceptions
2024-11-04 11:26:35,261:INFO:Importing libraries
2024-11-04 11:26:35,261:INFO:Copying training dataset
2024-11-04 11:26:35,264:INFO:Defining folds
2024-11-04 11:26:35,264:INFO:Declaring metric variables
2024-11-04 11:26:35,264:INFO:Importing untrained model
2024-11-04 11:26:35,264:INFO:Naive Bayes Imported successfully
2024-11-04 11:26:35,264:INFO:Starting cross validation
2024-11-04 11:26:35,266:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:35,388:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:35,392:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:35,400:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:35,413:INFO:Calculating mean and std
2024-11-04 11:26:35,414:INFO:Creating metrics dataframe
2024-11-04 11:26:35,415:INFO:Uploading results into container
2024-11-04 11:26:35,416:INFO:Uploading model into container now
2024-11-04 11:26:35,416:INFO:_master_model_container: 3
2024-11-04 11:26:35,416:INFO:_display_container: 2
2024-11-04 11:26:35,416:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-04 11:26:35,416:INFO:create_model() successfully completed......................................
2024-11-04 11:26:35,492:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:35,492:INFO:Creating metrics dataframe
2024-11-04 11:26:35,494:INFO:Initializing Decision Tree Classifier
2024-11-04 11:26:35,495:INFO:Total runtime is 0.06728856166203817 minutes
2024-11-04 11:26:35,495:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:35,495:INFO:Initializing create_model()
2024-11-04 11:26:35,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:35,495:INFO:Checking exceptions
2024-11-04 11:26:35,495:INFO:Importing libraries
2024-11-04 11:26:35,495:INFO:Copying training dataset
2024-11-04 11:26:35,498:INFO:Defining folds
2024-11-04 11:26:35,498:INFO:Declaring metric variables
2024-11-04 11:26:35,498:INFO:Importing untrained model
2024-11-04 11:26:35,499:INFO:Decision Tree Classifier Imported successfully
2024-11-04 11:26:35,499:INFO:Starting cross validation
2024-11-04 11:26:35,500:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:35,709:INFO:Calculating mean and std
2024-11-04 11:26:35,712:INFO:Creating metrics dataframe
2024-11-04 11:26:35,718:INFO:Uploading results into container
2024-11-04 11:26:35,720:INFO:Uploading model into container now
2024-11-04 11:26:35,722:INFO:_master_model_container: 4
2024-11-04 11:26:35,722:INFO:_display_container: 2
2024-11-04 11:26:35,723:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-04 11:26:35,723:INFO:create_model() successfully completed......................................
2024-11-04 11:26:35,843:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:35,843:INFO:Creating metrics dataframe
2024-11-04 11:26:35,847:INFO:Initializing SVM - Linear Kernel
2024-11-04 11:26:35,847:INFO:Total runtime is 0.07315795024236044 minutes
2024-11-04 11:26:35,847:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:35,847:INFO:Initializing create_model()
2024-11-04 11:26:35,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:35,847:INFO:Checking exceptions
2024-11-04 11:26:35,847:INFO:Importing libraries
2024-11-04 11:26:35,847:INFO:Copying training dataset
2024-11-04 11:26:35,851:INFO:Defining folds
2024-11-04 11:26:35,851:INFO:Declaring metric variables
2024-11-04 11:26:35,852:INFO:Importing untrained model
2024-11-04 11:26:35,852:INFO:SVM - Linear Kernel Imported successfully
2024-11-04 11:26:35,852:INFO:Starting cross validation
2024-11-04 11:26:35,854:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:36,010:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,017:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,023:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,025:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,030:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:36,043:INFO:Calculating mean and std
2024-11-04 11:26:36,044:INFO:Creating metrics dataframe
2024-11-04 11:26:36,045:INFO:Uploading results into container
2024-11-04 11:26:36,046:INFO:Uploading model into container now
2024-11-04 11:26:36,046:INFO:_master_model_container: 5
2024-11-04 11:26:36,046:INFO:_display_container: 2
2024-11-04 11:26:36,047:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-04 11:26:36,047:INFO:create_model() successfully completed......................................
2024-11-04 11:26:36,129:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:36,129:INFO:Creating metrics dataframe
2024-11-04 11:26:36,132:INFO:Initializing Ridge Classifier
2024-11-04 11:26:36,132:INFO:Total runtime is 0.07792127927144368 minutes
2024-11-04 11:26:36,133:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:36,133:INFO:Initializing create_model()
2024-11-04 11:26:36,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:36,133:INFO:Checking exceptions
2024-11-04 11:26:36,133:INFO:Importing libraries
2024-11-04 11:26:36,133:INFO:Copying training dataset
2024-11-04 11:26:36,135:INFO:Defining folds
2024-11-04 11:26:36,136:INFO:Declaring metric variables
2024-11-04 11:26:36,136:INFO:Importing untrained model
2024-11-04 11:26:36,136:INFO:Ridge Classifier Imported successfully
2024-11-04 11:26:36,136:INFO:Starting cross validation
2024-11-04 11:26:36,138:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:36,280:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,312:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,314:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,316:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:36,318:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:36,321:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:36,324:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:26:36,336:INFO:Calculating mean and std
2024-11-04 11:26:36,336:INFO:Creating metrics dataframe
2024-11-04 11:26:36,338:INFO:Uploading results into container
2024-11-04 11:26:36,339:INFO:Uploading model into container now
2024-11-04 11:26:36,339:INFO:_master_model_container: 6
2024-11-04 11:26:36,339:INFO:_display_container: 2
2024-11-04 11:26:36,339:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-04 11:26:36,339:INFO:create_model() successfully completed......................................
2024-11-04 11:26:36,415:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:36,415:INFO:Creating metrics dataframe
2024-11-04 11:26:36,417:INFO:Initializing Random Forest Classifier
2024-11-04 11:26:36,417:INFO:Total runtime is 0.0826703151067098 minutes
2024-11-04 11:26:36,418:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:36,418:INFO:Initializing create_model()
2024-11-04 11:26:36,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:36,418:INFO:Checking exceptions
2024-11-04 11:26:36,418:INFO:Importing libraries
2024-11-04 11:26:36,418:INFO:Copying training dataset
2024-11-04 11:26:36,420:INFO:Defining folds
2024-11-04 11:26:36,420:INFO:Declaring metric variables
2024-11-04 11:26:36,421:INFO:Importing untrained model
2024-11-04 11:26:36,421:INFO:Random Forest Classifier Imported successfully
2024-11-04 11:26:36,421:INFO:Starting cross validation
2024-11-04 11:26:36,423:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:36,915:INFO:Calculating mean and std
2024-11-04 11:26:36,915:INFO:Creating metrics dataframe
2024-11-04 11:26:36,917:INFO:Uploading results into container
2024-11-04 11:26:36,917:INFO:Uploading model into container now
2024-11-04 11:26:36,918:INFO:_master_model_container: 7
2024-11-04 11:26:36,918:INFO:_display_container: 2
2024-11-04 11:26:36,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-04 11:26:36,918:INFO:create_model() successfully completed......................................
2024-11-04 11:26:36,991:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:36,991:INFO:Creating metrics dataframe
2024-11-04 11:26:36,993:INFO:Initializing Quadratic Discriminant Analysis
2024-11-04 11:26:36,993:INFO:Total runtime is 0.09225944677988689 minutes
2024-11-04 11:26:36,993:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:36,993:INFO:Initializing create_model()
2024-11-04 11:26:36,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:36,993:INFO:Checking exceptions
2024-11-04 11:26:36,993:INFO:Importing libraries
2024-11-04 11:26:36,993:INFO:Copying training dataset
2024-11-04 11:26:36,996:INFO:Defining folds
2024-11-04 11:26:36,996:INFO:Declaring metric variables
2024-11-04 11:26:36,996:INFO:Importing untrained model
2024-11-04 11:26:36,996:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-04 11:26:36,996:INFO:Starting cross validation
2024-11-04 11:26:36,998:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:37,110:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:26:37,112:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:26:37,122:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:26:37,124:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:26:37,137:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,139:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,161:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,162:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,175:INFO:Calculating mean and std
2024-11-04 11:26:37,175:INFO:Creating metrics dataframe
2024-11-04 11:26:37,177:INFO:Uploading results into container
2024-11-04 11:26:37,178:INFO:Uploading model into container now
2024-11-04 11:26:37,178:INFO:_master_model_container: 8
2024-11-04 11:26:37,178:INFO:_display_container: 2
2024-11-04 11:26:37,178:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-04 11:26:37,178:INFO:create_model() successfully completed......................................
2024-11-04 11:26:37,244:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:37,244:INFO:Creating metrics dataframe
2024-11-04 11:26:37,246:INFO:Initializing Ada Boost Classifier
2024-11-04 11:26:37,246:INFO:Total runtime is 0.0964775323867798 minutes
2024-11-04 11:26:37,246:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:37,246:INFO:Initializing create_model()
2024-11-04 11:26:37,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:37,246:INFO:Checking exceptions
2024-11-04 11:26:37,246:INFO:Importing libraries
2024-11-04 11:26:37,246:INFO:Copying training dataset
2024-11-04 11:26:37,249:INFO:Defining folds
2024-11-04 11:26:37,249:INFO:Declaring metric variables
2024-11-04 11:26:37,249:INFO:Importing untrained model
2024-11-04 11:26:37,249:INFO:Ada Boost Classifier Imported successfully
2024-11-04 11:26:37,249:INFO:Starting cross validation
2024-11-04 11:26:37,251:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:37,342:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:26:37,353:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:26:37,355:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:26:37,356:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:26:37,439:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,448:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,451:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,452:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:37,468:INFO:Calculating mean and std
2024-11-04 11:26:37,468:INFO:Creating metrics dataframe
2024-11-04 11:26:37,470:INFO:Uploading results into container
2024-11-04 11:26:37,470:INFO:Uploading model into container now
2024-11-04 11:26:37,471:INFO:_master_model_container: 9
2024-11-04 11:26:37,471:INFO:_display_container: 2
2024-11-04 11:26:37,471:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-04 11:26:37,471:INFO:create_model() successfully completed......................................
2024-11-04 11:26:37,542:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:37,542:INFO:Creating metrics dataframe
2024-11-04 11:26:37,544:INFO:Initializing Gradient Boosting Classifier
2024-11-04 11:26:37,544:INFO:Total runtime is 0.1014468510945638 minutes
2024-11-04 11:26:37,544:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:37,544:INFO:Initializing create_model()
2024-11-04 11:26:37,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:37,545:INFO:Checking exceptions
2024-11-04 11:26:37,545:INFO:Importing libraries
2024-11-04 11:26:37,545:INFO:Copying training dataset
2024-11-04 11:26:37,547:INFO:Defining folds
2024-11-04 11:26:37,547:INFO:Declaring metric variables
2024-11-04 11:26:37,548:INFO:Importing untrained model
2024-11-04 11:26:37,548:INFO:Gradient Boosting Classifier Imported successfully
2024-11-04 11:26:37,548:INFO:Starting cross validation
2024-11-04 11:26:37,550:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:38,006:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,015:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,090:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,102:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,109:INFO:Calculating mean and std
2024-11-04 11:26:38,110:INFO:Creating metrics dataframe
2024-11-04 11:26:38,112:INFO:Uploading results into container
2024-11-04 11:26:38,112:INFO:Uploading model into container now
2024-11-04 11:26:38,112:INFO:_master_model_container: 10
2024-11-04 11:26:38,112:INFO:_display_container: 2
2024-11-04 11:26:38,113:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-04 11:26:38,113:INFO:create_model() successfully completed......................................
2024-11-04 11:26:38,178:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:38,178:INFO:Creating metrics dataframe
2024-11-04 11:26:38,180:INFO:Initializing Linear Discriminant Analysis
2024-11-04 11:26:38,180:INFO:Total runtime is 0.11204785903294881 minutes
2024-11-04 11:26:38,180:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:38,180:INFO:Initializing create_model()
2024-11-04 11:26:38,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:38,180:INFO:Checking exceptions
2024-11-04 11:26:38,180:INFO:Importing libraries
2024-11-04 11:26:38,180:INFO:Copying training dataset
2024-11-04 11:26:38,183:INFO:Defining folds
2024-11-04 11:26:38,183:INFO:Declaring metric variables
2024-11-04 11:26:38,183:INFO:Importing untrained model
2024-11-04 11:26:38,183:INFO:Linear Discriminant Analysis Imported successfully
2024-11-04 11:26:38,183:INFO:Starting cross validation
2024-11-04 11:26:38,185:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:38,293:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,293:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,313:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,313:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:26:38,331:INFO:Calculating mean and std
2024-11-04 11:26:38,331:INFO:Creating metrics dataframe
2024-11-04 11:26:38,333:INFO:Uploading results into container
2024-11-04 11:26:38,333:INFO:Uploading model into container now
2024-11-04 11:26:38,334:INFO:_master_model_container: 11
2024-11-04 11:26:38,334:INFO:_display_container: 2
2024-11-04 11:26:38,334:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-04 11:26:38,334:INFO:create_model() successfully completed......................................
2024-11-04 11:26:38,400:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:38,400:INFO:Creating metrics dataframe
2024-11-04 11:26:38,402:INFO:Initializing Extra Trees Classifier
2024-11-04 11:26:38,402:INFO:Total runtime is 0.11575011014938354 minutes
2024-11-04 11:26:38,402:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:38,402:INFO:Initializing create_model()
2024-11-04 11:26:38,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:38,403:INFO:Checking exceptions
2024-11-04 11:26:38,403:INFO:Importing libraries
2024-11-04 11:26:38,403:INFO:Copying training dataset
2024-11-04 11:26:38,405:INFO:Defining folds
2024-11-04 11:26:38,405:INFO:Declaring metric variables
2024-11-04 11:26:38,405:INFO:Importing untrained model
2024-11-04 11:26:38,405:INFO:Extra Trees Classifier Imported successfully
2024-11-04 11:26:38,405:INFO:Starting cross validation
2024-11-04 11:26:38,407:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:26:38,725:INFO:Calculating mean and std
2024-11-04 11:26:38,726:INFO:Creating metrics dataframe
2024-11-04 11:26:38,727:INFO:Uploading results into container
2024-11-04 11:26:38,727:INFO:Uploading model into container now
2024-11-04 11:26:38,727:INFO:_master_model_container: 12
2024-11-04 11:26:38,727:INFO:_display_container: 2
2024-11-04 11:26:38,728:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-04 11:26:38,728:INFO:create_model() successfully completed......................................
2024-11-04 11:26:38,793:INFO:SubProcess create_model() end ==================================
2024-11-04 11:26:38,793:INFO:Creating metrics dataframe
2024-11-04 11:26:38,795:INFO:Initializing Light Gradient Boosting Machine
2024-11-04 11:26:38,795:INFO:Total runtime is 0.12229493856430053 minutes
2024-11-04 11:26:38,795:INFO:SubProcess create_model() called ==================================
2024-11-04 11:26:38,795:INFO:Initializing create_model()
2024-11-04 11:26:38,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f983ec72910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f981db54990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:26:38,795:INFO:Checking exceptions
2024-11-04 11:26:38,795:INFO:Importing libraries
2024-11-04 11:26:38,795:INFO:Copying training dataset
2024-11-04 11:26:38,798:INFO:Defining folds
2024-11-04 11:26:38,798:INFO:Declaring metric variables
2024-11-04 11:26:38,798:INFO:Importing untrained model
2024-11-04 11:26:38,798:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-04 11:26:38,798:INFO:Starting cross validation
2024-11-04 11:26:38,800:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:28:59,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:28:59,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:28:59,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:28:59,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:29:00,086:INFO:PyCaret ClassificationExperiment
2024-11-04 11:29:00,086:INFO:Logging name: clf-default-name
2024-11-04 11:29:00,086:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:29:00,086:INFO:version 3.3.2
2024-11-04 11:29:00,086:INFO:Initializing setup()
2024-11-04 11:29:00,086:INFO:self.USI: 0a2e
2024-11-04 11:29:00,086:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'html_param', 'exp_id', 'target_param', '_ml_usecase', 'X', 'data', 'y_test', 'log_plots_param', 'memory', 'fold_shuffle_param', 'y_train', 'fold_generator', 'fix_imbalance', '_available_plots', 'y', 'n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'logging_param', 'gpu_param', 'pipeline', 'USI', 'exp_name_log'}
2024-11-04 11:29:00,086:INFO:Checking environment
2024-11-04 11:29:00,086:INFO:python_version: 3.11.2
2024-11-04 11:29:00,086:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:29:00,086:INFO:machine: x86_64
2024-11-04 11:29:00,087:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:29:00,087:INFO:Memory: svmem(total=16721211392, available=10263887872, percent=38.6, used=5953306624, free=4342157312, active=1881501696, inactive=9483411456, buffers=308264960, cached=6117482496, shared=155377664, slab=526561280)
2024-11-04 11:29:00,088:INFO:Physical Core: 4
2024-11-04 11:29:00,088:INFO:Logical Core: 8
2024-11-04 11:29:00,088:INFO:Checking libraries
2024-11-04 11:29:00,088:INFO:System:
2024-11-04 11:29:00,088:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:29:00,088:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:29:00,088:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:29:00,088:INFO:PyCaret required dependencies:
2024-11-04 11:29:00,106:INFO:                 pip: 23.0.1
2024-11-04 11:29:00,106:INFO:          setuptools: 66.1.1
2024-11-04 11:29:00,106:INFO:             pycaret: 3.3.2
2024-11-04 11:29:00,106:INFO:             IPython: 8.29.0
2024-11-04 11:29:00,106:INFO:          ipywidgets: 8.1.5
2024-11-04 11:29:00,106:INFO:                tqdm: 4.66.6
2024-11-04 11:29:00,106:INFO:               numpy: 1.26.4
2024-11-04 11:29:00,106:INFO:              pandas: 2.1.4
2024-11-04 11:29:00,106:INFO:              jinja2: 3.1.4
2024-11-04 11:29:00,106:INFO:               scipy: 1.11.4
2024-11-04 11:29:00,106:INFO:              joblib: 1.3.2
2024-11-04 11:29:00,106:INFO:             sklearn: 1.4.2
2024-11-04 11:29:00,106:INFO:                pyod: 2.0.2
2024-11-04 11:29:00,106:INFO:            imblearn: 0.12.4
2024-11-04 11:29:00,107:INFO:   category_encoders: 2.6.4
2024-11-04 11:29:00,107:INFO:            lightgbm: 4.5.0
2024-11-04 11:29:00,107:INFO:               numba: 0.60.0
2024-11-04 11:29:00,107:INFO:            requests: 2.32.3
2024-11-04 11:29:00,107:INFO:          matplotlib: 3.7.5
2024-11-04 11:29:00,107:INFO:          scikitplot: 0.3.7
2024-11-04 11:29:00,107:INFO:         yellowbrick: 1.5
2024-11-04 11:29:00,107:INFO:              plotly: 5.24.1
2024-11-04 11:29:00,107:INFO:    plotly-resampler: Not installed
2024-11-04 11:29:00,107:INFO:             kaleido: 0.2.1
2024-11-04 11:29:00,107:INFO:           schemdraw: 0.15
2024-11-04 11:29:00,107:INFO:         statsmodels: 0.14.4
2024-11-04 11:29:00,107:INFO:              sktime: 0.26.0
2024-11-04 11:29:00,107:INFO:               tbats: 1.1.3
2024-11-04 11:29:00,107:INFO:            pmdarima: 2.0.4
2024-11-04 11:29:00,107:INFO:              psutil: 6.1.0
2024-11-04 11:29:00,107:INFO:          markupsafe: 3.0.2
2024-11-04 11:29:00,107:INFO:             pickle5: Not installed
2024-11-04 11:29:00,107:INFO:         cloudpickle: 3.1.0
2024-11-04 11:29:00,107:INFO:         deprecation: 2.1.0
2024-11-04 11:29:00,107:INFO:              xxhash: 3.5.0
2024-11-04 11:29:00,107:INFO:           wurlitzer: 3.1.1
2024-11-04 11:29:00,107:INFO:PyCaret optional dependencies:
2024-11-04 11:29:00,125:INFO:                shap: Not installed
2024-11-04 11:29:00,125:INFO:           interpret: Not installed
2024-11-04 11:29:00,125:INFO:                umap: Not installed
2024-11-04 11:29:00,125:INFO:     ydata_profiling: Not installed
2024-11-04 11:29:00,125:INFO:  explainerdashboard: Not installed
2024-11-04 11:29:00,125:INFO:             autoviz: Not installed
2024-11-04 11:29:00,125:INFO:           fairlearn: Not installed
2024-11-04 11:29:00,125:INFO:          deepchecks: Not installed
2024-11-04 11:29:00,126:INFO:             xgboost: Not installed
2024-11-04 11:29:00,126:INFO:            catboost: Not installed
2024-11-04 11:29:00,126:INFO:              kmodes: Not installed
2024-11-04 11:29:00,126:INFO:             mlxtend: Not installed
2024-11-04 11:29:00,126:INFO:       statsforecast: Not installed
2024-11-04 11:29:00,126:INFO:        tune_sklearn: Not installed
2024-11-04 11:29:00,126:INFO:                 ray: Not installed
2024-11-04 11:29:00,126:INFO:            hyperopt: Not installed
2024-11-04 11:29:00,126:INFO:              optuna: Not installed
2024-11-04 11:29:00,126:INFO:               skopt: Not installed
2024-11-04 11:29:00,126:INFO:              mlflow: Not installed
2024-11-04 11:29:00,126:INFO:              gradio: Not installed
2024-11-04 11:29:00,126:INFO:             fastapi: Not installed
2024-11-04 11:29:00,126:INFO:             uvicorn: Not installed
2024-11-04 11:29:00,126:INFO:              m2cgen: Not installed
2024-11-04 11:29:00,126:INFO:           evidently: Not installed
2024-11-04 11:29:00,126:INFO:               fugue: Not installed
2024-11-04 11:29:00,126:INFO:           streamlit: Not installed
2024-11-04 11:29:00,126:INFO:             prophet: Not installed
2024-11-04 11:29:00,126:INFO:None
2024-11-04 11:29:00,126:INFO:Set up data.
2024-11-04 11:29:00,134:INFO:Set up folding strategy.
2024-11-04 11:29:00,134:INFO:Set up train/test split.
2024-11-04 11:29:00,141:INFO:Set up index.
2024-11-04 11:29:00,141:INFO:Assigning column types.
2024-11-04 11:29:00,144:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:29:00,186:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,189:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,301:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:29:00,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:00,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,419:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:29:00,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:00,543:INFO:Preparing preprocessing pipeline...
2024-11-04 11:29:00,544:INFO:Set up simple imputation.
2024-11-04 11:29:00,548:INFO:Set up encoding of categorical features.
2024-11-04 11:29:00,549:INFO:Set up column name cleaning.
2024-11-04 11:29:00,680:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:29:00,686:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:29:00,686:INFO:Creating final display dataframe.
2024-11-04 11:29:00,947:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                 4
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0a2e
2024-11-04 11:29:01,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,079:INFO:setup() successfully completed in 0.99s...............
2024-11-04 11:29:01,080:INFO:PyCaret ClassificationExperiment
2024-11-04 11:29:01,080:INFO:Logging name: clf-default-name
2024-11-04 11:29:01,080:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:29:01,080:INFO:version 3.3.2
2024-11-04 11:29:01,080:INFO:Initializing setup()
2024-11-04 11:29:01,080:INFO:self.USI: 28cb
2024-11-04 11:29:01,080:INFO:self._variable_keys: {'X_train', 'is_multiclass', 'html_param', 'exp_id', 'target_param', '_ml_usecase', 'X', 'data', 'y_test', 'log_plots_param', 'memory', 'fold_shuffle_param', 'y_train', 'fold_generator', 'fix_imbalance', '_available_plots', 'y', 'n_jobs_param', 'idx', 'fold_groups_param', 'seed', 'X_test', 'gpu_n_jobs_param', 'logging_param', 'gpu_param', 'pipeline', 'USI', 'exp_name_log'}
2024-11-04 11:29:01,080:INFO:Checking environment
2024-11-04 11:29:01,080:INFO:python_version: 3.11.2
2024-11-04 11:29:01,080:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:29:01,080:INFO:machine: x86_64
2024-11-04 11:29:01,080:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:29:01,080:INFO:Memory: svmem(total=16721211392, available=10245439488, percent=38.7, used=5971828736, free=4323667968, active=1881759744, inactive=9505173504, buffers=308264960, cached=6117449728, shared=155303936, slab=526553088)
2024-11-04 11:29:01,081:INFO:Physical Core: 4
2024-11-04 11:29:01,081:INFO:Logical Core: 8
2024-11-04 11:29:01,081:INFO:Checking libraries
2024-11-04 11:29:01,081:INFO:System:
2024-11-04 11:29:01,081:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:29:01,081:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:29:01,081:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:29:01,081:INFO:PyCaret required dependencies:
2024-11-04 11:29:01,081:INFO:                 pip: 23.0.1
2024-11-04 11:29:01,081:INFO:          setuptools: 66.1.1
2024-11-04 11:29:01,081:INFO:             pycaret: 3.3.2
2024-11-04 11:29:01,081:INFO:             IPython: 8.29.0
2024-11-04 11:29:01,081:INFO:          ipywidgets: 8.1.5
2024-11-04 11:29:01,081:INFO:                tqdm: 4.66.6
2024-11-04 11:29:01,081:INFO:               numpy: 1.26.4
2024-11-04 11:29:01,081:INFO:              pandas: 2.1.4
2024-11-04 11:29:01,081:INFO:              jinja2: 3.1.4
2024-11-04 11:29:01,081:INFO:               scipy: 1.11.4
2024-11-04 11:29:01,081:INFO:              joblib: 1.3.2
2024-11-04 11:29:01,081:INFO:             sklearn: 1.4.2
2024-11-04 11:29:01,081:INFO:                pyod: 2.0.2
2024-11-04 11:29:01,081:INFO:            imblearn: 0.12.4
2024-11-04 11:29:01,081:INFO:   category_encoders: 2.6.4
2024-11-04 11:29:01,081:INFO:            lightgbm: 4.5.0
2024-11-04 11:29:01,081:INFO:               numba: 0.60.0
2024-11-04 11:29:01,081:INFO:            requests: 2.32.3
2024-11-04 11:29:01,081:INFO:          matplotlib: 3.7.5
2024-11-04 11:29:01,081:INFO:          scikitplot: 0.3.7
2024-11-04 11:29:01,081:INFO:         yellowbrick: 1.5
2024-11-04 11:29:01,081:INFO:              plotly: 5.24.1
2024-11-04 11:29:01,081:INFO:    plotly-resampler: Not installed
2024-11-04 11:29:01,081:INFO:             kaleido: 0.2.1
2024-11-04 11:29:01,081:INFO:           schemdraw: 0.15
2024-11-04 11:29:01,081:INFO:         statsmodels: 0.14.4
2024-11-04 11:29:01,081:INFO:              sktime: 0.26.0
2024-11-04 11:29:01,081:INFO:               tbats: 1.1.3
2024-11-04 11:29:01,081:INFO:            pmdarima: 2.0.4
2024-11-04 11:29:01,081:INFO:              psutil: 6.1.0
2024-11-04 11:29:01,081:INFO:          markupsafe: 3.0.2
2024-11-04 11:29:01,082:INFO:             pickle5: Not installed
2024-11-04 11:29:01,082:INFO:         cloudpickle: 3.1.0
2024-11-04 11:29:01,082:INFO:         deprecation: 2.1.0
2024-11-04 11:29:01,082:INFO:              xxhash: 3.5.0
2024-11-04 11:29:01,082:INFO:           wurlitzer: 3.1.1
2024-11-04 11:29:01,082:INFO:PyCaret optional dependencies:
2024-11-04 11:29:01,082:INFO:                shap: Not installed
2024-11-04 11:29:01,082:INFO:           interpret: Not installed
2024-11-04 11:29:01,082:INFO:                umap: Not installed
2024-11-04 11:29:01,082:INFO:     ydata_profiling: Not installed
2024-11-04 11:29:01,082:INFO:  explainerdashboard: Not installed
2024-11-04 11:29:01,082:INFO:             autoviz: Not installed
2024-11-04 11:29:01,082:INFO:           fairlearn: Not installed
2024-11-04 11:29:01,082:INFO:          deepchecks: Not installed
2024-11-04 11:29:01,082:INFO:             xgboost: Not installed
2024-11-04 11:29:01,082:INFO:            catboost: Not installed
2024-11-04 11:29:01,082:INFO:              kmodes: Not installed
2024-11-04 11:29:01,082:INFO:             mlxtend: Not installed
2024-11-04 11:29:01,082:INFO:       statsforecast: Not installed
2024-11-04 11:29:01,082:INFO:        tune_sklearn: Not installed
2024-11-04 11:29:01,082:INFO:                 ray: Not installed
2024-11-04 11:29:01,082:INFO:            hyperopt: Not installed
2024-11-04 11:29:01,082:INFO:              optuna: Not installed
2024-11-04 11:29:01,082:INFO:               skopt: Not installed
2024-11-04 11:29:01,082:INFO:              mlflow: Not installed
2024-11-04 11:29:01,082:INFO:              gradio: Not installed
2024-11-04 11:29:01,082:INFO:             fastapi: Not installed
2024-11-04 11:29:01,082:INFO:             uvicorn: Not installed
2024-11-04 11:29:01,082:INFO:              m2cgen: Not installed
2024-11-04 11:29:01,082:INFO:           evidently: Not installed
2024-11-04 11:29:01,082:INFO:               fugue: Not installed
2024-11-04 11:29:01,082:INFO:           streamlit: Not installed
2024-11-04 11:29:01,082:INFO:             prophet: Not installed
2024-11-04 11:29:01,082:INFO:None
2024-11-04 11:29:01,082:INFO:Set up data.
2024-11-04 11:29:01,087:INFO:Set up folding strategy.
2024-11-04 11:29:01,088:INFO:Set up train/test split.
2024-11-04 11:29:01,092:INFO:Set up index.
2024-11-04 11:29:01,092:INFO:Assigning column types.
2024-11-04 11:29:01,094:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:29:01,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,190:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,212:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:29:01,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,315:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:29:01,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,341:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:29:01,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,464:INFO:Preparing preprocessing pipeline...
2024-11-04 11:29:01,465:INFO:Set up simple imputation.
2024-11-04 11:29:01,467:INFO:Set up encoding of categorical features.
2024-11-04 11:29:01,467:INFO:Set up column name cleaning.
2024-11-04 11:29:01,578:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:29:01,583:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:29:01,583:INFO:Creating final display dataframe.
2024-11-04 11:29:01,836:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              28cb
2024-11-04 11:29:01,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:29:01,964:INFO:setup() successfully completed in 0.88s...............
2024-11-04 11:29:01,964:INFO:Initializing compare_models()
2024-11-04 11:29:01,964:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-04 11:29:01,964:INFO:Checking exceptions
2024-11-04 11:29:01,966:INFO:Preparing display monitor
2024-11-04 11:29:01,970:INFO:Initializing Logistic Regression
2024-11-04 11:29:01,970:INFO:Total runtime is 1.5695889790852864e-06 minutes
2024-11-04 11:29:01,970:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:01,970:INFO:Initializing create_model()
2024-11-04 11:29:01,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:01,970:INFO:Checking exceptions
2024-11-04 11:29:01,970:INFO:Importing libraries
2024-11-04 11:29:01,970:INFO:Copying training dataset
2024-11-04 11:29:01,973:INFO:Defining folds
2024-11-04 11:29:01,973:INFO:Declaring metric variables
2024-11-04 11:29:01,973:INFO:Importing untrained model
2024-11-04 11:29:01,974:INFO:Logistic Regression Imported successfully
2024-11-04 11:29:01,974:INFO:Starting cross validation
2024-11-04 11:29:01,976:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:03,933:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:03,960:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:04,258:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:04,316:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:04,336:INFO:Calculating mean and std
2024-11-04 11:29:04,337:INFO:Creating metrics dataframe
2024-11-04 11:29:04,341:INFO:Uploading results into container
2024-11-04 11:29:04,342:INFO:Uploading model into container now
2024-11-04 11:29:04,342:INFO:_master_model_container: 1
2024-11-04 11:29:04,343:INFO:_display_container: 2
2024-11-04 11:29:04,343:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-04 11:29:04,343:INFO:create_model() successfully completed......................................
2024-11-04 11:29:04,454:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:04,454:INFO:Creating metrics dataframe
2024-11-04 11:29:04,456:INFO:Initializing K Neighbors Classifier
2024-11-04 11:29:04,456:INFO:Total runtime is 0.04144270420074463 minutes
2024-11-04 11:29:04,456:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:04,457:INFO:Initializing create_model()
2024-11-04 11:29:04,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:04,457:INFO:Checking exceptions
2024-11-04 11:29:04,457:INFO:Importing libraries
2024-11-04 11:29:04,457:INFO:Copying training dataset
2024-11-04 11:29:04,460:INFO:Defining folds
2024-11-04 11:29:04,460:INFO:Declaring metric variables
2024-11-04 11:29:04,460:INFO:Importing untrained model
2024-11-04 11:29:04,461:INFO:K Neighbors Classifier Imported successfully
2024-11-04 11:29:04,461:INFO:Starting cross validation
2024-11-04 11:29:04,462:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:06,143:INFO:Calculating mean and std
2024-11-04 11:29:06,144:INFO:Creating metrics dataframe
2024-11-04 11:29:06,147:INFO:Uploading results into container
2024-11-04 11:29:06,147:INFO:Uploading model into container now
2024-11-04 11:29:06,148:INFO:_master_model_container: 2
2024-11-04 11:29:06,148:INFO:_display_container: 2
2024-11-04 11:29:06,148:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-04 11:29:06,148:INFO:create_model() successfully completed......................................
2024-11-04 11:29:06,248:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:06,248:INFO:Creating metrics dataframe
2024-11-04 11:29:06,250:INFO:Initializing Naive Bayes
2024-11-04 11:29:06,250:INFO:Total runtime is 0.07133907079696655 minutes
2024-11-04 11:29:06,250:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:06,250:INFO:Initializing create_model()
2024-11-04 11:29:06,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:06,251:INFO:Checking exceptions
2024-11-04 11:29:06,251:INFO:Importing libraries
2024-11-04 11:29:06,251:INFO:Copying training dataset
2024-11-04 11:29:06,254:INFO:Defining folds
2024-11-04 11:29:06,255:INFO:Declaring metric variables
2024-11-04 11:29:06,255:INFO:Importing untrained model
2024-11-04 11:29:06,255:INFO:Naive Bayes Imported successfully
2024-11-04 11:29:06,255:INFO:Starting cross validation
2024-11-04 11:29:06,258:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:06,396:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:06,437:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:06,439:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:06,455:INFO:Calculating mean and std
2024-11-04 11:29:06,456:INFO:Creating metrics dataframe
2024-11-04 11:29:06,457:INFO:Uploading results into container
2024-11-04 11:29:06,458:INFO:Uploading model into container now
2024-11-04 11:29:06,458:INFO:_master_model_container: 3
2024-11-04 11:29:06,458:INFO:_display_container: 2
2024-11-04 11:29:06,458:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-04 11:29:06,458:INFO:create_model() successfully completed......................................
2024-11-04 11:29:06,530:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:06,530:INFO:Creating metrics dataframe
2024-11-04 11:29:06,532:INFO:Initializing Decision Tree Classifier
2024-11-04 11:29:06,532:INFO:Total runtime is 0.0760403593381246 minutes
2024-11-04 11:29:06,532:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:06,532:INFO:Initializing create_model()
2024-11-04 11:29:06,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:06,532:INFO:Checking exceptions
2024-11-04 11:29:06,532:INFO:Importing libraries
2024-11-04 11:29:06,532:INFO:Copying training dataset
2024-11-04 11:29:06,535:INFO:Defining folds
2024-11-04 11:29:06,535:INFO:Declaring metric variables
2024-11-04 11:29:06,535:INFO:Importing untrained model
2024-11-04 11:29:06,535:INFO:Decision Tree Classifier Imported successfully
2024-11-04 11:29:06,536:INFO:Starting cross validation
2024-11-04 11:29:06,538:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:06,684:INFO:Calculating mean and std
2024-11-04 11:29:06,685:INFO:Creating metrics dataframe
2024-11-04 11:29:06,687:INFO:Uploading results into container
2024-11-04 11:29:06,687:INFO:Uploading model into container now
2024-11-04 11:29:06,687:INFO:_master_model_container: 4
2024-11-04 11:29:06,687:INFO:_display_container: 2
2024-11-04 11:29:06,688:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-04 11:29:06,688:INFO:create_model() successfully completed......................................
2024-11-04 11:29:06,763:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:06,763:INFO:Creating metrics dataframe
2024-11-04 11:29:06,766:INFO:Initializing SVM - Linear Kernel
2024-11-04 11:29:06,766:INFO:Total runtime is 0.07994455099105835 minutes
2024-11-04 11:29:06,767:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:06,767:INFO:Initializing create_model()
2024-11-04 11:29:06,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:06,767:INFO:Checking exceptions
2024-11-04 11:29:06,767:INFO:Importing libraries
2024-11-04 11:29:06,767:INFO:Copying training dataset
2024-11-04 11:29:06,771:INFO:Defining folds
2024-11-04 11:29:06,771:INFO:Declaring metric variables
2024-11-04 11:29:06,771:INFO:Importing untrained model
2024-11-04 11:29:06,772:INFO:SVM - Linear Kernel Imported successfully
2024-11-04 11:29:06,772:INFO:Starting cross validation
2024-11-04 11:29:06,773:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:06,922:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:06,930:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:06,951:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:06,955:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:06,956:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:06,970:INFO:Calculating mean and std
2024-11-04 11:29:06,971:INFO:Creating metrics dataframe
2024-11-04 11:29:06,972:INFO:Uploading results into container
2024-11-04 11:29:06,973:INFO:Uploading model into container now
2024-11-04 11:29:06,973:INFO:_master_model_container: 5
2024-11-04 11:29:06,973:INFO:_display_container: 2
2024-11-04 11:29:06,974:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-04 11:29:06,974:INFO:create_model() successfully completed......................................
2024-11-04 11:29:07,044:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:07,044:INFO:Creating metrics dataframe
2024-11-04 11:29:07,046:INFO:Initializing Ridge Classifier
2024-11-04 11:29:07,046:INFO:Total runtime is 0.08460923035939534 minutes
2024-11-04 11:29:07,046:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:07,047:INFO:Initializing create_model()
2024-11-04 11:29:07,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:07,047:INFO:Checking exceptions
2024-11-04 11:29:07,047:INFO:Importing libraries
2024-11-04 11:29:07,047:INFO:Copying training dataset
2024-11-04 11:29:07,049:INFO:Defining folds
2024-11-04 11:29:07,049:INFO:Declaring metric variables
2024-11-04 11:29:07,049:INFO:Importing untrained model
2024-11-04 11:29:07,050:INFO:Ridge Classifier Imported successfully
2024-11-04 11:29:07,050:INFO:Starting cross validation
2024-11-04 11:29:07,052:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:07,186:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:07,188:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:07,190:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:07,224:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:07,231:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:07,234:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:07,240:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:29:07,250:INFO:Calculating mean and std
2024-11-04 11:29:07,252:INFO:Creating metrics dataframe
2024-11-04 11:29:07,254:INFO:Uploading results into container
2024-11-04 11:29:07,254:INFO:Uploading model into container now
2024-11-04 11:29:07,255:INFO:_master_model_container: 6
2024-11-04 11:29:07,255:INFO:_display_container: 2
2024-11-04 11:29:07,255:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-04 11:29:07,255:INFO:create_model() successfully completed......................................
2024-11-04 11:29:07,328:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:07,328:INFO:Creating metrics dataframe
2024-11-04 11:29:07,330:INFO:Initializing Random Forest Classifier
2024-11-04 11:29:07,330:INFO:Total runtime is 0.08934191465377807 minutes
2024-11-04 11:29:07,330:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:07,330:INFO:Initializing create_model()
2024-11-04 11:29:07,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:07,331:INFO:Checking exceptions
2024-11-04 11:29:07,331:INFO:Importing libraries
2024-11-04 11:29:07,331:INFO:Copying training dataset
2024-11-04 11:29:07,333:INFO:Defining folds
2024-11-04 11:29:07,333:INFO:Declaring metric variables
2024-11-04 11:29:07,334:INFO:Importing untrained model
2024-11-04 11:29:07,334:INFO:Random Forest Classifier Imported successfully
2024-11-04 11:29:07,334:INFO:Starting cross validation
2024-11-04 11:29:07,336:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:07,816:INFO:Calculating mean and std
2024-11-04 11:29:07,816:INFO:Creating metrics dataframe
2024-11-04 11:29:07,817:INFO:Uploading results into container
2024-11-04 11:29:07,818:INFO:Uploading model into container now
2024-11-04 11:29:07,818:INFO:_master_model_container: 7
2024-11-04 11:29:07,818:INFO:_display_container: 2
2024-11-04 11:29:07,819:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-04 11:29:07,819:INFO:create_model() successfully completed......................................
2024-11-04 11:29:07,886:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:07,886:INFO:Creating metrics dataframe
2024-11-04 11:29:07,888:INFO:Initializing Quadratic Discriminant Analysis
2024-11-04 11:29:07,888:INFO:Total runtime is 0.09863728682200112 minutes
2024-11-04 11:29:07,888:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:07,888:INFO:Initializing create_model()
2024-11-04 11:29:07,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:07,888:INFO:Checking exceptions
2024-11-04 11:29:07,888:INFO:Importing libraries
2024-11-04 11:29:07,888:INFO:Copying training dataset
2024-11-04 11:29:07,891:INFO:Defining folds
2024-11-04 11:29:07,891:INFO:Declaring metric variables
2024-11-04 11:29:07,891:INFO:Importing untrained model
2024-11-04 11:29:07,891:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-04 11:29:07,891:INFO:Starting cross validation
2024-11-04 11:29:07,893:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:07,994:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:29:07,996:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:29:08,018:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:29:08,023:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:29:08,026:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,027:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,059:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,066:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,081:INFO:Calculating mean and std
2024-11-04 11:29:08,082:INFO:Creating metrics dataframe
2024-11-04 11:29:08,083:INFO:Uploading results into container
2024-11-04 11:29:08,084:INFO:Uploading model into container now
2024-11-04 11:29:08,084:INFO:_master_model_container: 8
2024-11-04 11:29:08,084:INFO:_display_container: 2
2024-11-04 11:29:08,084:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-04 11:29:08,084:INFO:create_model() successfully completed......................................
2024-11-04 11:29:08,153:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:08,153:INFO:Creating metrics dataframe
2024-11-04 11:29:08,155:INFO:Initializing Ada Boost Classifier
2024-11-04 11:29:08,155:INFO:Total runtime is 0.10308752059936523 minutes
2024-11-04 11:29:08,155:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:08,155:INFO:Initializing create_model()
2024-11-04 11:29:08,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:08,155:INFO:Checking exceptions
2024-11-04 11:29:08,156:INFO:Importing libraries
2024-11-04 11:29:08,156:INFO:Copying training dataset
2024-11-04 11:29:08,159:INFO:Defining folds
2024-11-04 11:29:08,159:INFO:Declaring metric variables
2024-11-04 11:29:08,159:INFO:Importing untrained model
2024-11-04 11:29:08,159:INFO:Ada Boost Classifier Imported successfully
2024-11-04 11:29:08,160:INFO:Starting cross validation
2024-11-04 11:29:08,162:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:08,259:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:29:08,265:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:29:08,292:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:29:08,297:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:29:08,366:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,378:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,435:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,439:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:08,452:INFO:Calculating mean and std
2024-11-04 11:29:08,452:INFO:Creating metrics dataframe
2024-11-04 11:29:08,454:INFO:Uploading results into container
2024-11-04 11:29:08,454:INFO:Uploading model into container now
2024-11-04 11:29:08,454:INFO:_master_model_container: 9
2024-11-04 11:29:08,454:INFO:_display_container: 2
2024-11-04 11:29:08,455:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-04 11:29:08,455:INFO:create_model() successfully completed......................................
2024-11-04 11:29:08,527:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:08,527:INFO:Creating metrics dataframe
2024-11-04 11:29:08,529:INFO:Initializing Gradient Boosting Classifier
2024-11-04 11:29:08,529:INFO:Total runtime is 0.10932273864746093 minutes
2024-11-04 11:29:08,529:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:08,529:INFO:Initializing create_model()
2024-11-04 11:29:08,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:08,529:INFO:Checking exceptions
2024-11-04 11:29:08,529:INFO:Importing libraries
2024-11-04 11:29:08,529:INFO:Copying training dataset
2024-11-04 11:29:08,532:INFO:Defining folds
2024-11-04 11:29:08,532:INFO:Declaring metric variables
2024-11-04 11:29:08,532:INFO:Importing untrained model
2024-11-04 11:29:08,532:INFO:Gradient Boosting Classifier Imported successfully
2024-11-04 11:29:08,532:INFO:Starting cross validation
2024-11-04 11:29:08,534:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:09,015:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,015:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,032:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,042:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,054:INFO:Calculating mean and std
2024-11-04 11:29:09,054:INFO:Creating metrics dataframe
2024-11-04 11:29:09,056:INFO:Uploading results into container
2024-11-04 11:29:09,056:INFO:Uploading model into container now
2024-11-04 11:29:09,056:INFO:_master_model_container: 10
2024-11-04 11:29:09,056:INFO:_display_container: 2
2024-11-04 11:29:09,057:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-04 11:29:09,057:INFO:create_model() successfully completed......................................
2024-11-04 11:29:09,127:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:09,127:INFO:Creating metrics dataframe
2024-11-04 11:29:09,130:INFO:Initializing Linear Discriminant Analysis
2024-11-04 11:29:09,130:INFO:Total runtime is 0.11933446327845255 minutes
2024-11-04 11:29:09,130:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:09,130:INFO:Initializing create_model()
2024-11-04 11:29:09,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:09,130:INFO:Checking exceptions
2024-11-04 11:29:09,130:INFO:Importing libraries
2024-11-04 11:29:09,130:INFO:Copying training dataset
2024-11-04 11:29:09,133:INFO:Defining folds
2024-11-04 11:29:09,133:INFO:Declaring metric variables
2024-11-04 11:29:09,133:INFO:Importing untrained model
2024-11-04 11:29:09,133:INFO:Linear Discriminant Analysis Imported successfully
2024-11-04 11:29:09,134:INFO:Starting cross validation
2024-11-04 11:29:09,135:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:09,307:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,307:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,309:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,309:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:29:09,322:INFO:Calculating mean and std
2024-11-04 11:29:09,323:INFO:Creating metrics dataframe
2024-11-04 11:29:09,324:INFO:Uploading results into container
2024-11-04 11:29:09,325:INFO:Uploading model into container now
2024-11-04 11:29:09,325:INFO:_master_model_container: 11
2024-11-04 11:29:09,326:INFO:_display_container: 2
2024-11-04 11:29:09,326:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-04 11:29:09,326:INFO:create_model() successfully completed......................................
2024-11-04 11:29:09,394:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:09,395:INFO:Creating metrics dataframe
2024-11-04 11:29:09,397:INFO:Initializing Extra Trees Classifier
2024-11-04 11:29:09,397:INFO:Total runtime is 0.12378817399342855 minutes
2024-11-04 11:29:09,397:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:09,397:INFO:Initializing create_model()
2024-11-04 11:29:09,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:09,398:INFO:Checking exceptions
2024-11-04 11:29:09,398:INFO:Importing libraries
2024-11-04 11:29:09,398:INFO:Copying training dataset
2024-11-04 11:29:09,401:INFO:Defining folds
2024-11-04 11:29:09,401:INFO:Declaring metric variables
2024-11-04 11:29:09,401:INFO:Importing untrained model
2024-11-04 11:29:09,402:INFO:Extra Trees Classifier Imported successfully
2024-11-04 11:29:09,402:INFO:Starting cross validation
2024-11-04 11:29:09,404:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:29:09,753:INFO:Calculating mean and std
2024-11-04 11:29:09,754:INFO:Creating metrics dataframe
2024-11-04 11:29:09,756:INFO:Uploading results into container
2024-11-04 11:29:09,756:INFO:Uploading model into container now
2024-11-04 11:29:09,757:INFO:_master_model_container: 12
2024-11-04 11:29:09,757:INFO:_display_container: 2
2024-11-04 11:29:09,757:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-04 11:29:09,757:INFO:create_model() successfully completed......................................
2024-11-04 11:29:09,824:INFO:SubProcess create_model() end ==================================
2024-11-04 11:29:09,824:INFO:Creating metrics dataframe
2024-11-04 11:29:09,826:INFO:Initializing Light Gradient Boosting Machine
2024-11-04 11:29:09,827:INFO:Total runtime is 0.1309473435084025 minutes
2024-11-04 11:29:09,827:INFO:SubProcess create_model() called ==================================
2024-11-04 11:29:09,827:INFO:Initializing create_model()
2024-11-04 11:29:09,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb465202a90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb443c344d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:29:09,827:INFO:Checking exceptions
2024-11-04 11:29:09,827:INFO:Importing libraries
2024-11-04 11:29:09,827:INFO:Copying training dataset
2024-11-04 11:29:09,829:INFO:Defining folds
2024-11-04 11:29:09,829:INFO:Declaring metric variables
2024-11-04 11:29:09,829:INFO:Importing untrained model
2024-11-04 11:29:09,830:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-04 11:29:09,830:INFO:Starting cross validation
2024-11-04 11:29:09,831:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:37:47,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:37:47,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:37:47,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:37:47,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:37:51,058:INFO:PyCaret ClassificationExperiment
2024-11-04 11:37:51,058:INFO:Logging name: clf-default-name
2024-11-04 11:37:51,059:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:37:51,059:INFO:version 3.3.2
2024-11-04 11:37:51,059:INFO:Initializing setup()
2024-11-04 11:37:51,059:INFO:self.USI: 5cbf
2024-11-04 11:37:51,059:INFO:self._variable_keys: {'X_test', 'logging_param', 'seed', 'X', 'exp_name_log', 'target_param', 'n_jobs_param', 'X_train', 'y', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'memory', 'fold_generator', 'fold_groups_param', 'fix_imbalance', 'log_plots_param', 'USI', 'idx', 'y_test', 'gpu_n_jobs_param', 'is_multiclass', 'pipeline', '_available_plots', 'exp_id', 'gpu_param', 'data', 'html_param'}
2024-11-04 11:37:51,059:INFO:Checking environment
2024-11-04 11:37:51,059:INFO:python_version: 3.11.2
2024-11-04 11:37:51,059:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:37:51,060:INFO:machine: x86_64
2024-11-04 11:37:51,060:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:37:51,060:INFO:Memory: svmem(total=16721211392, available=10133319680, percent=39.4, used=6124294144, free=3938074624, active=1965309952, inactive=9786236928, buffers=319991808, cached=6338850816, shared=114958336, slab=546045952)
2024-11-04 11:37:51,062:INFO:Physical Core: 4
2024-11-04 11:37:51,062:INFO:Logical Core: 8
2024-11-04 11:37:51,062:INFO:Checking libraries
2024-11-04 11:37:51,063:INFO:System:
2024-11-04 11:37:51,063:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:37:51,063:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:37:51,063:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:37:51,063:INFO:PyCaret required dependencies:
2024-11-04 11:37:51,088:INFO:                 pip: 23.0.1
2024-11-04 11:37:51,089:INFO:          setuptools: 66.1.1
2024-11-04 11:37:51,089:INFO:             pycaret: 3.3.2
2024-11-04 11:37:51,089:INFO:             IPython: 8.29.0
2024-11-04 11:37:51,089:INFO:          ipywidgets: 8.1.5
2024-11-04 11:37:51,089:INFO:                tqdm: 4.66.6
2024-11-04 11:37:51,089:INFO:               numpy: 1.26.4
2024-11-04 11:37:51,089:INFO:              pandas: 2.1.4
2024-11-04 11:37:51,089:INFO:              jinja2: 3.1.4
2024-11-04 11:37:51,089:INFO:               scipy: 1.11.4
2024-11-04 11:37:51,089:INFO:              joblib: 1.3.2
2024-11-04 11:37:51,089:INFO:             sklearn: 1.4.2
2024-11-04 11:37:51,089:INFO:                pyod: 2.0.2
2024-11-04 11:37:51,089:INFO:            imblearn: 0.12.4
2024-11-04 11:37:51,089:INFO:   category_encoders: 2.6.4
2024-11-04 11:37:51,089:INFO:            lightgbm: 4.5.0
2024-11-04 11:37:51,089:INFO:               numba: 0.60.0
2024-11-04 11:37:51,089:INFO:            requests: 2.32.3
2024-11-04 11:37:51,089:INFO:          matplotlib: 3.7.5
2024-11-04 11:37:51,089:INFO:          scikitplot: 0.3.7
2024-11-04 11:37:51,089:INFO:         yellowbrick: 1.5
2024-11-04 11:37:51,089:INFO:              plotly: 5.24.1
2024-11-04 11:37:51,089:INFO:    plotly-resampler: Not installed
2024-11-04 11:37:51,089:INFO:             kaleido: 0.2.1
2024-11-04 11:37:51,089:INFO:           schemdraw: 0.15
2024-11-04 11:37:51,089:INFO:         statsmodels: 0.14.4
2024-11-04 11:37:51,089:INFO:              sktime: 0.26.0
2024-11-04 11:37:51,089:INFO:               tbats: 1.1.3
2024-11-04 11:37:51,090:INFO:            pmdarima: 2.0.4
2024-11-04 11:37:51,090:INFO:              psutil: 6.1.0
2024-11-04 11:37:51,090:INFO:          markupsafe: 3.0.2
2024-11-04 11:37:51,090:INFO:             pickle5: Not installed
2024-11-04 11:37:51,090:INFO:         cloudpickle: 3.1.0
2024-11-04 11:37:51,090:INFO:         deprecation: 2.1.0
2024-11-04 11:37:51,090:INFO:              xxhash: 3.5.0
2024-11-04 11:37:51,090:INFO:           wurlitzer: 3.1.1
2024-11-04 11:37:51,090:INFO:PyCaret optional dependencies:
2024-11-04 11:37:51,107:INFO:                shap: Not installed
2024-11-04 11:37:51,107:INFO:           interpret: Not installed
2024-11-04 11:37:51,107:INFO:                umap: Not installed
2024-11-04 11:37:51,107:INFO:     ydata_profiling: Not installed
2024-11-04 11:37:51,107:INFO:  explainerdashboard: Not installed
2024-11-04 11:37:51,107:INFO:             autoviz: Not installed
2024-11-04 11:37:51,107:INFO:           fairlearn: Not installed
2024-11-04 11:37:51,108:INFO:          deepchecks: Not installed
2024-11-04 11:37:51,108:INFO:             xgboost: Not installed
2024-11-04 11:37:51,108:INFO:            catboost: Not installed
2024-11-04 11:37:51,108:INFO:              kmodes: Not installed
2024-11-04 11:37:51,108:INFO:             mlxtend: Not installed
2024-11-04 11:37:51,108:INFO:       statsforecast: Not installed
2024-11-04 11:37:51,108:INFO:        tune_sklearn: Not installed
2024-11-04 11:37:51,108:INFO:                 ray: Not installed
2024-11-04 11:37:51,108:INFO:            hyperopt: Not installed
2024-11-04 11:37:51,108:INFO:              optuna: Not installed
2024-11-04 11:37:51,108:INFO:               skopt: Not installed
2024-11-04 11:37:51,108:INFO:              mlflow: Not installed
2024-11-04 11:37:51,108:INFO:              gradio: Not installed
2024-11-04 11:37:51,108:INFO:             fastapi: Not installed
2024-11-04 11:37:51,108:INFO:             uvicorn: Not installed
2024-11-04 11:37:51,108:INFO:              m2cgen: Not installed
2024-11-04 11:37:51,108:INFO:           evidently: Not installed
2024-11-04 11:37:51,108:INFO:               fugue: Not installed
2024-11-04 11:37:51,108:INFO:           streamlit: Not installed
2024-11-04 11:37:51,108:INFO:             prophet: Not installed
2024-11-04 11:37:51,108:INFO:None
2024-11-04 11:37:51,108:INFO:Set up data.
2024-11-04 11:37:51,117:INFO:Set up folding strategy.
2024-11-04 11:37:51,118:INFO:Set up train/test split.
2024-11-04 11:37:51,124:INFO:Set up index.
2024-11-04 11:37:51,124:INFO:Assigning column types.
2024-11-04 11:37:51,128:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:37:51,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,247:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,270:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:37:51,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,362:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:37:51,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,384:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:37:51,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,503:INFO:Preparing preprocessing pipeline...
2024-11-04 11:37:51,503:INFO:Set up simple imputation.
2024-11-04 11:37:51,506:INFO:Set up encoding of categorical features.
2024-11-04 11:37:51,506:INFO:Set up column name cleaning.
2024-11-04 11:37:51,622:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:37:51,627:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:37:51,627:INFO:Creating final display dataframe.
2024-11-04 11:37:51,878:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                 4
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              5cbf
2024-11-04 11:37:51,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:51,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:52,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:52,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:37:52,013:INFO:setup() successfully completed in 0.96s...............
2024-11-04 11:38:18,929:INFO:PyCaret ClassificationExperiment
2024-11-04 11:38:18,929:INFO:Logging name: clf-default-name
2024-11-04 11:38:18,930:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-04 11:38:18,930:INFO:version 3.3.2
2024-11-04 11:38:18,930:INFO:Initializing setup()
2024-11-04 11:38:18,930:INFO:self.USI: 0d1f
2024-11-04 11:38:18,930:INFO:self._variable_keys: {'X_test', 'logging_param', 'seed', 'X', 'exp_name_log', 'target_param', 'n_jobs_param', 'X_train', 'y', 'y_train', 'fold_shuffle_param', '_ml_usecase', 'memory', 'fold_generator', 'fold_groups_param', 'fix_imbalance', 'log_plots_param', 'USI', 'idx', 'y_test', 'gpu_n_jobs_param', 'is_multiclass', 'pipeline', '_available_plots', 'exp_id', 'gpu_param', 'data', 'html_param'}
2024-11-04 11:38:18,931:INFO:Checking environment
2024-11-04 11:38:18,931:INFO:python_version: 3.11.2
2024-11-04 11:38:18,931:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-04 11:38:18,931:INFO:machine: x86_64
2024-11-04 11:38:18,931:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:38:18,932:INFO:Memory: svmem(total=16721211392, available=10153107456, percent=39.3, used=6105149440, free=3957821440, active=1965404160, inactive=9766260736, buffers=320090112, cached=6338150400, shared=114315264, slab=545935360)
2024-11-04 11:38:18,934:INFO:Physical Core: 4
2024-11-04 11:38:18,934:INFO:Logical Core: 8
2024-11-04 11:38:18,934:INFO:Checking libraries
2024-11-04 11:38:18,934:INFO:System:
2024-11-04 11:38:18,935:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-04 11:38:18,935:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-04 11:38:18,935:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-04 11:38:18,935:INFO:PyCaret required dependencies:
2024-11-04 11:38:18,935:INFO:                 pip: 23.0.1
2024-11-04 11:38:18,935:INFO:          setuptools: 66.1.1
2024-11-04 11:38:18,935:INFO:             pycaret: 3.3.2
2024-11-04 11:38:18,935:INFO:             IPython: 8.29.0
2024-11-04 11:38:18,936:INFO:          ipywidgets: 8.1.5
2024-11-04 11:38:18,936:INFO:                tqdm: 4.66.6
2024-11-04 11:38:18,936:INFO:               numpy: 1.26.4
2024-11-04 11:38:18,936:INFO:              pandas: 2.1.4
2024-11-04 11:38:18,936:INFO:              jinja2: 3.1.4
2024-11-04 11:38:18,936:INFO:               scipy: 1.11.4
2024-11-04 11:38:18,936:INFO:              joblib: 1.3.2
2024-11-04 11:38:18,936:INFO:             sklearn: 1.4.2
2024-11-04 11:38:18,936:INFO:                pyod: 2.0.2
2024-11-04 11:38:18,936:INFO:            imblearn: 0.12.4
2024-11-04 11:38:18,937:INFO:   category_encoders: 2.6.4
2024-11-04 11:38:18,937:INFO:            lightgbm: 4.5.0
2024-11-04 11:38:18,937:INFO:               numba: 0.60.0
2024-11-04 11:38:18,937:INFO:            requests: 2.32.3
2024-11-04 11:38:18,937:INFO:          matplotlib: 3.7.5
2024-11-04 11:38:18,937:INFO:          scikitplot: 0.3.7
2024-11-04 11:38:18,937:INFO:         yellowbrick: 1.5
2024-11-04 11:38:18,937:INFO:              plotly: 5.24.1
2024-11-04 11:38:18,937:INFO:    plotly-resampler: Not installed
2024-11-04 11:38:18,938:INFO:             kaleido: 0.2.1
2024-11-04 11:38:18,938:INFO:           schemdraw: 0.15
2024-11-04 11:38:18,938:INFO:         statsmodels: 0.14.4
2024-11-04 11:38:18,938:INFO:              sktime: 0.26.0
2024-11-04 11:38:18,938:INFO:               tbats: 1.1.3
2024-11-04 11:38:18,938:INFO:            pmdarima: 2.0.4
2024-11-04 11:38:18,938:INFO:              psutil: 6.1.0
2024-11-04 11:38:18,938:INFO:          markupsafe: 3.0.2
2024-11-04 11:38:18,938:INFO:             pickle5: Not installed
2024-11-04 11:38:18,938:INFO:         cloudpickle: 3.1.0
2024-11-04 11:38:18,939:INFO:         deprecation: 2.1.0
2024-11-04 11:38:18,939:INFO:              xxhash: 3.5.0
2024-11-04 11:38:18,939:INFO:           wurlitzer: 3.1.1
2024-11-04 11:38:18,939:INFO:PyCaret optional dependencies:
2024-11-04 11:38:18,939:INFO:                shap: Not installed
2024-11-04 11:38:18,939:INFO:           interpret: Not installed
2024-11-04 11:38:18,939:INFO:                umap: Not installed
2024-11-04 11:38:18,939:INFO:     ydata_profiling: Not installed
2024-11-04 11:38:18,939:INFO:  explainerdashboard: Not installed
2024-11-04 11:38:18,940:INFO:             autoviz: Not installed
2024-11-04 11:38:18,940:INFO:           fairlearn: Not installed
2024-11-04 11:38:18,940:INFO:          deepchecks: Not installed
2024-11-04 11:38:18,940:INFO:             xgboost: Not installed
2024-11-04 11:38:18,940:INFO:            catboost: Not installed
2024-11-04 11:38:18,940:INFO:              kmodes: Not installed
2024-11-04 11:38:18,940:INFO:             mlxtend: Not installed
2024-11-04 11:38:18,941:INFO:       statsforecast: Not installed
2024-11-04 11:38:18,941:INFO:        tune_sklearn: Not installed
2024-11-04 11:38:18,941:INFO:                 ray: Not installed
2024-11-04 11:38:18,941:INFO:            hyperopt: Not installed
2024-11-04 11:38:18,941:INFO:              optuna: Not installed
2024-11-04 11:38:18,941:INFO:               skopt: Not installed
2024-11-04 11:38:18,941:INFO:              mlflow: Not installed
2024-11-04 11:38:18,942:INFO:              gradio: Not installed
2024-11-04 11:38:18,942:INFO:             fastapi: Not installed
2024-11-04 11:38:18,942:INFO:             uvicorn: Not installed
2024-11-04 11:38:18,942:INFO:              m2cgen: Not installed
2024-11-04 11:38:18,942:INFO:           evidently: Not installed
2024-11-04 11:38:18,942:INFO:               fugue: Not installed
2024-11-04 11:38:18,942:INFO:           streamlit: Not installed
2024-11-04 11:38:18,942:INFO:             prophet: Not installed
2024-11-04 11:38:18,942:INFO:None
2024-11-04 11:38:18,942:INFO:Set up data.
2024-11-04 11:38:18,958:INFO:Set up folding strategy.
2024-11-04 11:38:18,958:INFO:Set up train/test split.
2024-11-04 11:38:18,964:INFO:Set up index.
2024-11-04 11:38:18,965:INFO:Assigning column types.
2024-11-04 11:38:18,970:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-04 11:38:19,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,034:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,130:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-04 11:38:19,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-04 11:38:19,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,239:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-04 11:38:19,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,348:INFO:Preparing preprocessing pipeline...
2024-11-04 11:38:19,349:INFO:Set up simple imputation.
2024-11-04 11:38:19,351:INFO:Set up encoding of categorical features.
2024-11-04 11:38:19,352:INFO:Set up column name cleaning.
2024-11-04 11:38:19,466:INFO:Finished creating preprocessing pipeline.
2024-11-04 11:38:19,472:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-04 11:38:19,472:INFO:Creating final display dataframe.
2024-11-04 11:38:19,726:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 10)
4        Transformed data shape         (372, 32)
5   Transformed train set shape         (260, 32)
6    Transformed test set shape         (112, 32)
7          Categorical features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12     Maximum one-hot encoding                25
13              Encoding method              None
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0d1f
2024-11-04 11:38:19,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-04 11:38:19,855:INFO:setup() successfully completed in 0.93s...............
2024-11-04 11:38:26,957:INFO:Initializing compare_models()
2024-11-04 11:38:26,958:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-04 11:38:26,958:INFO:Checking exceptions
2024-11-04 11:38:26,968:INFO:Preparing display monitor
2024-11-04 11:38:26,999:INFO:Initializing Logistic Regression
2024-11-04 11:38:26,999:INFO:Total runtime is 2.86102294921875e-06 minutes
2024-11-04 11:38:27,002:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:27,003:INFO:Initializing create_model()
2024-11-04 11:38:27,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:27,003:INFO:Checking exceptions
2024-11-04 11:38:27,003:INFO:Importing libraries
2024-11-04 11:38:27,003:INFO:Copying training dataset
2024-11-04 11:38:27,008:INFO:Defining folds
2024-11-04 11:38:27,008:INFO:Declaring metric variables
2024-11-04 11:38:27,011:INFO:Importing untrained model
2024-11-04 11:38:27,015:INFO:Logistic Regression Imported successfully
2024-11-04 11:38:27,024:INFO:Starting cross validation
2024-11-04 11:38:27,028:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:29,061:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:29,199:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:29,262:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:29,375:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:29,386:INFO:Calculating mean and std
2024-11-04 11:38:29,387:INFO:Creating metrics dataframe
2024-11-04 11:38:29,391:INFO:Uploading results into container
2024-11-04 11:38:29,392:INFO:Uploading model into container now
2024-11-04 11:38:29,392:INFO:_master_model_container: 1
2024-11-04 11:38:29,392:INFO:_display_container: 2
2024-11-04 11:38:29,393:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-04 11:38:29,393:INFO:create_model() successfully completed......................................
2024-11-04 11:38:29,508:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:29,508:INFO:Creating metrics dataframe
2024-11-04 11:38:29,515:INFO:Initializing K Neighbors Classifier
2024-11-04 11:38:29,515:INFO:Total runtime is 0.041946160793304446 minutes
2024-11-04 11:38:29,518:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:29,519:INFO:Initializing create_model()
2024-11-04 11:38:29,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:29,519:INFO:Checking exceptions
2024-11-04 11:38:29,519:INFO:Importing libraries
2024-11-04 11:38:29,519:INFO:Copying training dataset
2024-11-04 11:38:29,525:INFO:Defining folds
2024-11-04 11:38:29,525:INFO:Declaring metric variables
2024-11-04 11:38:29,529:INFO:Importing untrained model
2024-11-04 11:38:29,532:INFO:K Neighbors Classifier Imported successfully
2024-11-04 11:38:29,541:INFO:Starting cross validation
2024-11-04 11:38:29,544:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:31,347:INFO:Calculating mean and std
2024-11-04 11:38:31,348:INFO:Creating metrics dataframe
2024-11-04 11:38:31,350:INFO:Uploading results into container
2024-11-04 11:38:31,351:INFO:Uploading model into container now
2024-11-04 11:38:31,351:INFO:_master_model_container: 2
2024-11-04 11:38:31,351:INFO:_display_container: 2
2024-11-04 11:38:31,351:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-04 11:38:31,352:INFO:create_model() successfully completed......................................
2024-11-04 11:38:31,440:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:31,440:INFO:Creating metrics dataframe
2024-11-04 11:38:31,446:INFO:Initializing Naive Bayes
2024-11-04 11:38:31,446:INFO:Total runtime is 0.07412230173746745 minutes
2024-11-04 11:38:31,450:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:31,450:INFO:Initializing create_model()
2024-11-04 11:38:31,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:31,450:INFO:Checking exceptions
2024-11-04 11:38:31,450:INFO:Importing libraries
2024-11-04 11:38:31,450:INFO:Copying training dataset
2024-11-04 11:38:31,455:INFO:Defining folds
2024-11-04 11:38:31,455:INFO:Declaring metric variables
2024-11-04 11:38:31,459:INFO:Importing untrained model
2024-11-04 11:38:31,462:INFO:Naive Bayes Imported successfully
2024-11-04 11:38:31,470:INFO:Starting cross validation
2024-11-04 11:38:31,474:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:31,617:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:31,620:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:31,660:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:31,673:INFO:Calculating mean and std
2024-11-04 11:38:31,674:INFO:Creating metrics dataframe
2024-11-04 11:38:31,677:INFO:Uploading results into container
2024-11-04 11:38:31,678:INFO:Uploading model into container now
2024-11-04 11:38:31,679:INFO:_master_model_container: 3
2024-11-04 11:38:31,679:INFO:_display_container: 2
2024-11-04 11:38:31,679:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-04 11:38:31,679:INFO:create_model() successfully completed......................................
2024-11-04 11:38:31,755:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:31,755:INFO:Creating metrics dataframe
2024-11-04 11:38:31,763:INFO:Initializing Decision Tree Classifier
2024-11-04 11:38:31,764:INFO:Total runtime is 0.07941530148188274 minutes
2024-11-04 11:38:31,766:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:31,767:INFO:Initializing create_model()
2024-11-04 11:38:31,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:31,767:INFO:Checking exceptions
2024-11-04 11:38:31,767:INFO:Importing libraries
2024-11-04 11:38:31,767:INFO:Copying training dataset
2024-11-04 11:38:31,770:INFO:Defining folds
2024-11-04 11:38:31,770:INFO:Declaring metric variables
2024-11-04 11:38:31,774:INFO:Importing untrained model
2024-11-04 11:38:31,778:INFO:Decision Tree Classifier Imported successfully
2024-11-04 11:38:31,784:INFO:Starting cross validation
2024-11-04 11:38:31,787:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:31,977:INFO:Calculating mean and std
2024-11-04 11:38:31,977:INFO:Creating metrics dataframe
2024-11-04 11:38:31,979:INFO:Uploading results into container
2024-11-04 11:38:31,979:INFO:Uploading model into container now
2024-11-04 11:38:31,980:INFO:_master_model_container: 4
2024-11-04 11:38:31,980:INFO:_display_container: 2
2024-11-04 11:38:31,980:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-04 11:38:31,980:INFO:create_model() successfully completed......................................
2024-11-04 11:38:32,055:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:32,055:INFO:Creating metrics dataframe
2024-11-04 11:38:32,061:INFO:Initializing SVM - Linear Kernel
2024-11-04 11:38:32,061:INFO:Total runtime is 0.08437683979670207 minutes
2024-11-04 11:38:32,065:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:32,065:INFO:Initializing create_model()
2024-11-04 11:38:32,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:32,066:INFO:Checking exceptions
2024-11-04 11:38:32,066:INFO:Importing libraries
2024-11-04 11:38:32,066:INFO:Copying training dataset
2024-11-04 11:38:32,070:INFO:Defining folds
2024-11-04 11:38:32,070:INFO:Declaring metric variables
2024-11-04 11:38:32,073:INFO:Importing untrained model
2024-11-04 11:38:32,077:INFO:SVM - Linear Kernel Imported successfully
2024-11-04 11:38:32,085:INFO:Starting cross validation
2024-11-04 11:38:32,087:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:32,238:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,241:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,244:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,245:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:32,255:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,266:INFO:Calculating mean and std
2024-11-04 11:38:32,268:INFO:Creating metrics dataframe
2024-11-04 11:38:32,270:INFO:Uploading results into container
2024-11-04 11:38:32,271:INFO:Uploading model into container now
2024-11-04 11:38:32,271:INFO:_master_model_container: 5
2024-11-04 11:38:32,271:INFO:_display_container: 2
2024-11-04 11:38:32,272:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-04 11:38:32,272:INFO:create_model() successfully completed......................................
2024-11-04 11:38:32,348:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:32,349:INFO:Creating metrics dataframe
2024-11-04 11:38:32,355:INFO:Initializing Ridge Classifier
2024-11-04 11:38:32,355:INFO:Total runtime is 0.08928008476893108 minutes
2024-11-04 11:38:32,358:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:32,359:INFO:Initializing create_model()
2024-11-04 11:38:32,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:32,359:INFO:Checking exceptions
2024-11-04 11:38:32,359:INFO:Importing libraries
2024-11-04 11:38:32,359:INFO:Copying training dataset
2024-11-04 11:38:32,363:INFO:Defining folds
2024-11-04 11:38:32,363:INFO:Declaring metric variables
2024-11-04 11:38:32,366:INFO:Importing untrained model
2024-11-04 11:38:32,369:INFO:Ridge Classifier Imported successfully
2024-11-04 11:38:32,377:INFO:Starting cross validation
2024-11-04 11:38:32,379:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:32,511:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,512:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,517:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:32,549:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,552:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:32,556:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:32,558:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:38:32,566:INFO:Calculating mean and std
2024-11-04 11:38:32,567:INFO:Creating metrics dataframe
2024-11-04 11:38:32,570:INFO:Uploading results into container
2024-11-04 11:38:32,570:INFO:Uploading model into container now
2024-11-04 11:38:32,570:INFO:_master_model_container: 6
2024-11-04 11:38:32,570:INFO:_display_container: 2
2024-11-04 11:38:32,570:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-04 11:38:32,571:INFO:create_model() successfully completed......................................
2024-11-04 11:38:32,643:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:32,644:INFO:Creating metrics dataframe
2024-11-04 11:38:32,651:INFO:Initializing Random Forest Classifier
2024-11-04 11:38:32,651:INFO:Total runtime is 0.09420786301294963 minutes
2024-11-04 11:38:32,654:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:32,655:INFO:Initializing create_model()
2024-11-04 11:38:32,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:32,655:INFO:Checking exceptions
2024-11-04 11:38:32,655:INFO:Importing libraries
2024-11-04 11:38:32,655:INFO:Copying training dataset
2024-11-04 11:38:32,658:INFO:Defining folds
2024-11-04 11:38:32,658:INFO:Declaring metric variables
2024-11-04 11:38:32,661:INFO:Importing untrained model
2024-11-04 11:38:32,664:INFO:Random Forest Classifier Imported successfully
2024-11-04 11:38:32,671:INFO:Starting cross validation
2024-11-04 11:38:32,675:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:33,126:INFO:Calculating mean and std
2024-11-04 11:38:33,127:INFO:Creating metrics dataframe
2024-11-04 11:38:33,129:INFO:Uploading results into container
2024-11-04 11:38:33,129:INFO:Uploading model into container now
2024-11-04 11:38:33,129:INFO:_master_model_container: 7
2024-11-04 11:38:33,129:INFO:_display_container: 2
2024-11-04 11:38:33,130:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-04 11:38:33,130:INFO:create_model() successfully completed......................................
2024-11-04 11:38:33,204:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:33,205:INFO:Creating metrics dataframe
2024-11-04 11:38:33,213:INFO:Initializing Quadratic Discriminant Analysis
2024-11-04 11:38:33,213:INFO:Total runtime is 0.10356875658035279 minutes
2024-11-04 11:38:33,215:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:33,216:INFO:Initializing create_model()
2024-11-04 11:38:33,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:33,216:INFO:Checking exceptions
2024-11-04 11:38:33,216:INFO:Importing libraries
2024-11-04 11:38:33,216:INFO:Copying training dataset
2024-11-04 11:38:33,219:INFO:Defining folds
2024-11-04 11:38:33,219:INFO:Declaring metric variables
2024-11-04 11:38:33,222:INFO:Importing untrained model
2024-11-04 11:38:33,226:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-04 11:38:33,233:INFO:Starting cross validation
2024-11-04 11:38:33,237:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:33,351:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:38:33,356:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:38:33,376:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:38:33,379:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-04 11:38:33,389:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,396:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,420:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,422:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,438:INFO:Calculating mean and std
2024-11-04 11:38:33,438:INFO:Creating metrics dataframe
2024-11-04 11:38:33,441:INFO:Uploading results into container
2024-11-04 11:38:33,442:INFO:Uploading model into container now
2024-11-04 11:38:33,442:INFO:_master_model_container: 8
2024-11-04 11:38:33,442:INFO:_display_container: 2
2024-11-04 11:38:33,442:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-04 11:38:33,442:INFO:create_model() successfully completed......................................
2024-11-04 11:38:33,531:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:33,531:INFO:Creating metrics dataframe
2024-11-04 11:38:33,539:INFO:Initializing Ada Boost Classifier
2024-11-04 11:38:33,539:INFO:Total runtime is 0.10901459058125815 minutes
2024-11-04 11:38:33,542:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:33,543:INFO:Initializing create_model()
2024-11-04 11:38:33,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:33,543:INFO:Checking exceptions
2024-11-04 11:38:33,543:INFO:Importing libraries
2024-11-04 11:38:33,543:INFO:Copying training dataset
2024-11-04 11:38:33,546:INFO:Defining folds
2024-11-04 11:38:33,546:INFO:Declaring metric variables
2024-11-04 11:38:33,551:INFO:Importing untrained model
2024-11-04 11:38:33,555:INFO:Ada Boost Classifier Imported successfully
2024-11-04 11:38:33,562:INFO:Starting cross validation
2024-11-04 11:38:33,565:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:33,687:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:38:33,696:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:38:33,697:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:38:33,699:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-04 11:38:33,794:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,809:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,811:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,811:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:33,825:INFO:Calculating mean and std
2024-11-04 11:38:33,826:INFO:Creating metrics dataframe
2024-11-04 11:38:33,828:INFO:Uploading results into container
2024-11-04 11:38:33,828:INFO:Uploading model into container now
2024-11-04 11:38:33,829:INFO:_master_model_container: 9
2024-11-04 11:38:33,829:INFO:_display_container: 2
2024-11-04 11:38:33,829:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-04 11:38:33,829:INFO:create_model() successfully completed......................................
2024-11-04 11:38:33,909:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:33,909:INFO:Creating metrics dataframe
2024-11-04 11:38:33,918:INFO:Initializing Gradient Boosting Classifier
2024-11-04 11:38:33,918:INFO:Total runtime is 0.11532211303710939 minutes
2024-11-04 11:38:33,922:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:33,922:INFO:Initializing create_model()
2024-11-04 11:38:33,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:33,922:INFO:Checking exceptions
2024-11-04 11:38:33,922:INFO:Importing libraries
2024-11-04 11:38:33,922:INFO:Copying training dataset
2024-11-04 11:38:33,925:INFO:Defining folds
2024-11-04 11:38:33,925:INFO:Declaring metric variables
2024-11-04 11:38:33,928:INFO:Importing untrained model
2024-11-04 11:38:33,933:INFO:Gradient Boosting Classifier Imported successfully
2024-11-04 11:38:33,942:INFO:Starting cross validation
2024-11-04 11:38:33,945:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:34,465:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,479:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,613:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,621:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,637:INFO:Calculating mean and std
2024-11-04 11:38:34,638:INFO:Creating metrics dataframe
2024-11-04 11:38:34,640:INFO:Uploading results into container
2024-11-04 11:38:34,641:INFO:Uploading model into container now
2024-11-04 11:38:34,641:INFO:_master_model_container: 10
2024-11-04 11:38:34,641:INFO:_display_container: 2
2024-11-04 11:38:34,642:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-04 11:38:34,642:INFO:create_model() successfully completed......................................
2024-11-04 11:38:34,716:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:34,716:INFO:Creating metrics dataframe
2024-11-04 11:38:34,725:INFO:Initializing Linear Discriminant Analysis
2024-11-04 11:38:34,725:INFO:Total runtime is 0.12876780430475873 minutes
2024-11-04 11:38:34,728:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:34,729:INFO:Initializing create_model()
2024-11-04 11:38:34,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:34,729:INFO:Checking exceptions
2024-11-04 11:38:34,729:INFO:Importing libraries
2024-11-04 11:38:34,729:INFO:Copying training dataset
2024-11-04 11:38:34,733:INFO:Defining folds
2024-11-04 11:38:34,733:INFO:Declaring metric variables
2024-11-04 11:38:34,738:INFO:Importing untrained model
2024-11-04 11:38:34,741:INFO:Linear Discriminant Analysis Imported successfully
2024-11-04 11:38:34,752:INFO:Starting cross validation
2024-11-04 11:38:34,755:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:34,890:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,912:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,930:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,934:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-04 11:38:34,955:INFO:Calculating mean and std
2024-11-04 11:38:34,957:INFO:Creating metrics dataframe
2024-11-04 11:38:34,964:INFO:Uploading results into container
2024-11-04 11:38:34,965:INFO:Uploading model into container now
2024-11-04 11:38:34,966:INFO:_master_model_container: 11
2024-11-04 11:38:34,967:INFO:_display_container: 2
2024-11-04 11:38:34,967:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-04 11:38:34,968:INFO:create_model() successfully completed......................................
2024-11-04 11:38:35,084:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:35,085:INFO:Creating metrics dataframe
2024-11-04 11:38:35,096:INFO:Initializing Extra Trees Classifier
2024-11-04 11:38:35,096:INFO:Total runtime is 0.134952453772227 minutes
2024-11-04 11:38:35,099:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:35,100:INFO:Initializing create_model()
2024-11-04 11:38:35,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:35,100:INFO:Checking exceptions
2024-11-04 11:38:35,100:INFO:Importing libraries
2024-11-04 11:38:35,100:INFO:Copying training dataset
2024-11-04 11:38:35,104:INFO:Defining folds
2024-11-04 11:38:35,105:INFO:Declaring metric variables
2024-11-04 11:38:35,107:INFO:Importing untrained model
2024-11-04 11:38:35,111:INFO:Extra Trees Classifier Imported successfully
2024-11-04 11:38:35,119:INFO:Starting cross validation
2024-11-04 11:38:35,122:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:38:35,512:INFO:Calculating mean and std
2024-11-04 11:38:35,512:INFO:Creating metrics dataframe
2024-11-04 11:38:35,514:INFO:Uploading results into container
2024-11-04 11:38:35,515:INFO:Uploading model into container now
2024-11-04 11:38:35,515:INFO:_master_model_container: 12
2024-11-04 11:38:35,516:INFO:_display_container: 2
2024-11-04 11:38:35,516:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-04 11:38:35,516:INFO:create_model() successfully completed......................................
2024-11-04 11:38:35,591:INFO:SubProcess create_model() end ==================================
2024-11-04 11:38:35,591:INFO:Creating metrics dataframe
2024-11-04 11:38:35,598:INFO:Initializing Light Gradient Boosting Machine
2024-11-04 11:38:35,598:INFO:Total runtime is 0.14332181215286258 minutes
2024-11-04 11:38:35,602:INFO:SubProcess create_model() called ==================================
2024-11-04 11:38:35,602:INFO:Initializing create_model()
2024-11-04 11:38:35,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:38:35,602:INFO:Checking exceptions
2024-11-04 11:38:35,602:INFO:Importing libraries
2024-11-04 11:38:35,602:INFO:Copying training dataset
2024-11-04 11:38:35,606:INFO:Defining folds
2024-11-04 11:38:35,606:INFO:Declaring metric variables
2024-11-04 11:38:35,608:INFO:Importing untrained model
2024-11-04 11:38:35,611:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-04 11:38:35,618:INFO:Starting cross validation
2024-11-04 11:38:35,621:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:48:02,819:INFO:Calculating mean and std
2024-11-04 11:48:02,820:INFO:Creating metrics dataframe
2024-11-04 11:48:02,822:INFO:Uploading results into container
2024-11-04 11:48:02,823:INFO:Uploading model into container now
2024-11-04 11:48:02,823:INFO:_master_model_container: 13
2024-11-04 11:48:02,823:INFO:_display_container: 2
2024-11-04 11:48:02,824:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-04 11:48:02,824:INFO:create_model() successfully completed......................................
2024-11-04 11:48:02,913:INFO:SubProcess create_model() end ==================================
2024-11-04 11:48:02,913:INFO:Creating metrics dataframe
2024-11-04 11:48:02,924:INFO:Initializing Dummy Classifier
2024-11-04 11:48:02,924:INFO:Total runtime is 9.59874997138977 minutes
2024-11-04 11:48:02,926:INFO:SubProcess create_model() called ==================================
2024-11-04 11:48:02,926:INFO:Initializing create_model()
2024-11-04 11:48:02,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f307f774950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:48:02,926:INFO:Checking exceptions
2024-11-04 11:48:02,927:INFO:Importing libraries
2024-11-04 11:48:02,927:INFO:Copying training dataset
2024-11-04 11:48:02,931:INFO:Defining folds
2024-11-04 11:48:02,931:INFO:Declaring metric variables
2024-11-04 11:48:02,934:INFO:Importing untrained model
2024-11-04 11:48:02,939:INFO:Dummy Classifier Imported successfully
2024-11-04 11:48:02,945:INFO:Starting cross validation
2024-11-04 11:48:02,949:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-04 11:48:03,163:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:48:03,303:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:48:03,309:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:48:03,315:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-04 11:48:03,328:INFO:Calculating mean and std
2024-11-04 11:48:03,330:INFO:Creating metrics dataframe
2024-11-04 11:48:03,332:INFO:Uploading results into container
2024-11-04 11:48:03,333:INFO:Uploading model into container now
2024-11-04 11:48:03,333:INFO:_master_model_container: 14
2024-11-04 11:48:03,333:INFO:_display_container: 2
2024-11-04 11:48:03,334:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-04 11:48:03,334:INFO:create_model() successfully completed......................................
2024-11-04 11:48:03,448:INFO:SubProcess create_model() end ==================================
2024-11-04 11:48:03,448:INFO:Creating metrics dataframe
2024-11-04 11:48:03,461:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-04 11:48:03,472:INFO:Initializing create_model()
2024-11-04 11:48:03,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-04 11:48:03,472:INFO:Checking exceptions
2024-11-04 11:48:03,474:INFO:Importing libraries
2024-11-04 11:48:03,474:INFO:Copying training dataset
2024-11-04 11:48:03,480:INFO:Defining folds
2024-11-04 11:48:03,480:INFO:Declaring metric variables
2024-11-04 11:48:03,480:INFO:Importing untrained model
2024-11-04 11:48:03,480:INFO:Declaring custom model
2024-11-04 11:48:03,481:INFO:Ridge Classifier Imported successfully
2024-11-04 11:48:03,483:INFO:Cross validation set to False
2024-11-04 11:48:03,484:INFO:Fitting Model
2024-11-04 11:48:03,575:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-04 11:48:03,575:INFO:create_model() successfully completed......................................
2024-11-04 11:48:03,692:INFO:_master_model_container: 14
2024-11-04 11:48:03,692:INFO:_display_container: 2
2024-11-04 11:48:03,692:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-04 11:48:03,692:INFO:compare_models() successfully completed......................................
2024-11-04 11:57:54,426:INFO:Initializing save_model()
2024-11-04 11:57:54,426:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), model_name=modelo_agotamiento, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-11-04 11:57:54,426:INFO:Adding model into prep_pipe
2024-11-04 11:57:54,443:INFO:modelo_agotamiento.pkl saved in current working directory
2024-11-04 11:57:54,449:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-11-04 11:57:54,449:INFO:save_model() successfully completed......................................
2024-11-04 11:58:26,507:INFO:Initializing save_model()
2024-11-04 11:58:26,508:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), model_name=modelo-SA45-ECE, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-11-04 11:58:26,508:INFO:Adding model into prep_pipe
2024-11-04 11:58:26,527:INFO:modelo-SA45-ECE.pkl saved in current working directory
2024-11-04 11:58:26,535:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-11-04 11:58:26,535:INFO:save_model() successfully completed......................................
2024-11-04 11:59:59,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:59:59,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:59:59,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 11:59:59,780:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:00:00,218:INFO:Initializing load_model()
2024-11-04 12:00:00,218:INFO:load_model(model_name=modelo_agotamiento, platform=None, authentication=None, verbose=True)
2024-11-04 12:00:21,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:00:21,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:00:21,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:00:21,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:00:21,701:INFO:Initializing load_model()
2024-11-04 12:00:21,701:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:00:21,734:INFO:Initializing predict_model()
2024-11-04 12:00:21,735:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc65dd16e50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc697095300>)
2024-11-04 12:00:21,735:INFO:Checking exceptions
2024-11-04 12:00:21,735:INFO:Preloading libraries
2024-11-04 12:00:21,735:INFO:Set up data.
2024-11-04 12:00:21,738:INFO:Set up index.
2024-11-04 12:01:31,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:31,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:31,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:31,397:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:31,868:INFO:Initializing load_model()
2024-11-04 12:01:31,868:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:01:31,899:INFO:Initializing predict_model()
2024-11-04 12:01:31,899:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb9dbb5bf90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fba14f99300>)
2024-11-04 12:01:31,899:INFO:Checking exceptions
2024-11-04 12:01:31,899:INFO:Preloading libraries
2024-11-04 12:01:31,900:INFO:Set up data.
2024-11-04 12:01:31,902:INFO:Set up index.
2024-11-04 12:01:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:51,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:51,522:INFO:Initializing load_model()
2024-11-04 12:01:51,522:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:01:51,552:INFO:Initializing predict_model()
2024-11-04 12:01:51,553:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f413f16e690>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f4178599300>)
2024-11-04 12:01:51,553:INFO:Checking exceptions
2024-11-04 12:01:51,553:INFO:Preloading libraries
2024-11-04 12:01:51,553:INFO:Set up data.
2024-11-04 12:01:51,556:INFO:Set up index.
2024-11-04 12:01:58,797:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:58,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:58,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:58,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:01:59,252:INFO:Initializing load_model()
2024-11-04 12:01:59,252:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:01:59,282:INFO:Initializing predict_model()
2024-11-04 12:01:59,282:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9f3d977e10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9f76c95300>)
2024-11-04 12:01:59,282:INFO:Checking exceptions
2024-11-04 12:01:59,283:INFO:Preloading libraries
2024-11-04 12:01:59,283:INFO:Set up data.
2024-11-04 12:01:59,285:INFO:Set up index.
2024-11-04 12:02:44,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:02:44,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:02:44,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:02:44,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:02:45,323:INFO:Initializing load_model()
2024-11-04 12:02:45,323:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:02:45,352:INFO:Initializing predict_model()
2024-11-04 12:02:45,352:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6301033e90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f6336379300>)
2024-11-04 12:02:45,352:INFO:Checking exceptions
2024-11-04 12:02:45,352:INFO:Preloading libraries
2024-11-04 12:02:45,353:INFO:Set up data.
2024-11-04 12:02:45,357:INFO:Set up index.
2024-11-04 12:04:54,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:04:54,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:04:54,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:04:54,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:04:54,991:INFO:Initializing load_model()
2024-11-04 12:04:54,991:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:04:55,018:INFO:Initializing predict_model()
2024-11-04 12:04:55,018:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa5ed74bf50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa626a95300>)
2024-11-04 12:04:55,018:INFO:Checking exceptions
2024-11-04 12:04:55,018:INFO:Preloading libraries
2024-11-04 12:04:55,019:INFO:Set up data.
2024-11-04 12:04:55,021:INFO:Set up index.
2024-11-04 12:05:00,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:05:00,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:05:00,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:05:00,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-04 12:05:00,809:INFO:Initializing load_model()
2024-11-04 12:05:00,809:INFO:load_model(model_name=modelo-SA45-ECE, platform=None, authentication=None, verbose=True)
2024-11-04 12:05:00,838:INFO:Initializing predict_model()
2024-11-04 12:05:00,838:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f364cfc7e90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=[], transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Somatización', 'Obsesión/com',
                                             'Sen. Emocio.', 'Depresión',
                                             'Ansiedad', 'Hostilidad',
                                             'Ans. Fóbica', 'Ideación Paran.',
                                             'Psicoticismo'],
                                    transformer=SimpleImputer(strategy='most_freque...
                                             'Psicoticismo'],
                                    transformer=OneHotEncoder(cols=['Somatización',
                                                                    'Obsesión/com',
                                                                    'Sen. '
                                                                    'Emocio.',
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('trained_model', RidgeClassifier(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3682295300>)
2024-11-04 12:05:00,838:INFO:Checking exceptions
2024-11-04 12:05:00,838:INFO:Preloading libraries
2024-11-04 12:05:00,839:INFO:Set up data.
2024-11-04 12:05:00,841:INFO:Set up index.
2024-11-04 12:07:21,395:INFO:Initializing plot_model()
2024-11-04 12:07:21,396:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f305faec2d0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-11-04 12:07:21,397:INFO:Checking exceptions
2024-11-04 12:07:21,409:INFO:Preloading libraries
2024-11-04 12:07:21,410:INFO:Copying training dataset
2024-11-04 12:07:21,410:INFO:Plot type: confusion_matrix
2024-11-04 12:07:21,761:INFO:Fitting Model
2024-11-04 12:07:21,762:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-11-04 12:07:21,762:INFO:Scoring test/hold-out set
2024-11-04 12:07:22,049:INFO:Visual Rendered Successfully
2024-11-04 12:07:22,129:INFO:plot_model() successfully completed......................................
2024-11-11 09:38:51,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-11 09:38:51,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-11 09:38:51,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-11 09:38:51,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-11 09:38:59,459:INFO:PyCaret ClassificationExperiment
2024-11-11 09:38:59,459:INFO:Logging name: clf-default-name
2024-11-11 09:38:59,459:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-11 09:38:59,459:INFO:version 3.3.2
2024-11-11 09:38:59,459:INFO:Initializing setup()
2024-11-11 09:38:59,459:INFO:self.USI: 1923
2024-11-11 09:38:59,459:INFO:self._variable_keys: {'_ml_usecase', 'X', 'fold_shuffle_param', '_available_plots', 'X_train', 'y_train', 'seed', 'target_param', 'memory', 'n_jobs_param', 'USI', 'exp_id', 'exp_name_log', 'pipeline', 'gpu_param', 'data', 'logging_param', 'fix_imbalance', 'gpu_n_jobs_param', 'X_test', 'idx', 'y', 'html_param', 'log_plots_param', 'fold_groups_param', 'fold_generator', 'y_test', 'is_multiclass'}
2024-11-11 09:38:59,459:INFO:Checking environment
2024-11-11 09:38:59,459:INFO:python_version: 3.11.2
2024-11-11 09:38:59,459:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-11 09:38:59,459:INFO:machine: x86_64
2024-11-11 09:38:59,459:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-11 09:38:59,460:INFO:Memory: svmem(total=16721203200, available=10087202816, percent=39.7, used=6145228800, free=5725507584, active=1480114176, inactive=8465965056, buffers=496222208, cached=4354244608, shared=139919360, slab=543014912)
2024-11-11 09:38:59,461:INFO:Physical Core: 4
2024-11-11 09:38:59,461:INFO:Logical Core: 8
2024-11-11 09:38:59,461:INFO:Checking libraries
2024-11-11 09:38:59,461:INFO:System:
2024-11-11 09:38:59,461:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-11 09:38:59,461:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-11 09:38:59,461:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-11 09:38:59,461:INFO:PyCaret required dependencies:
2024-11-11 09:38:59,660:INFO:                 pip: 23.0.1
2024-11-11 09:38:59,660:INFO:          setuptools: 66.1.1
2024-11-11 09:38:59,660:INFO:             pycaret: 3.3.2
2024-11-11 09:38:59,660:INFO:             IPython: 8.29.0
2024-11-11 09:38:59,660:INFO:          ipywidgets: 8.1.5
2024-11-11 09:38:59,660:INFO:                tqdm: 4.66.6
2024-11-11 09:38:59,660:INFO:               numpy: 1.26.4
2024-11-11 09:38:59,660:INFO:              pandas: 2.1.4
2024-11-11 09:38:59,660:INFO:              jinja2: 3.1.4
2024-11-11 09:38:59,660:INFO:               scipy: 1.11.4
2024-11-11 09:38:59,660:INFO:              joblib: 1.3.2
2024-11-11 09:38:59,660:INFO:             sklearn: 1.4.2
2024-11-11 09:38:59,660:INFO:                pyod: 2.0.2
2024-11-11 09:38:59,660:INFO:            imblearn: 0.12.4
2024-11-11 09:38:59,660:INFO:   category_encoders: 2.6.4
2024-11-11 09:38:59,660:INFO:            lightgbm: 4.5.0
2024-11-11 09:38:59,660:INFO:               numba: 0.60.0
2024-11-11 09:38:59,661:INFO:            requests: 2.32.3
2024-11-11 09:38:59,661:INFO:          matplotlib: 3.7.5
2024-11-11 09:38:59,661:INFO:          scikitplot: 0.3.7
2024-11-11 09:38:59,661:INFO:         yellowbrick: 1.5
2024-11-11 09:38:59,661:INFO:              plotly: 5.24.1
2024-11-11 09:38:59,661:INFO:    plotly-resampler: Not installed
2024-11-11 09:38:59,661:INFO:             kaleido: 0.2.1
2024-11-11 09:38:59,661:INFO:           schemdraw: 0.15
2024-11-11 09:38:59,661:INFO:         statsmodels: 0.14.4
2024-11-11 09:38:59,661:INFO:              sktime: 0.26.0
2024-11-11 09:38:59,661:INFO:               tbats: 1.1.3
2024-11-11 09:38:59,661:INFO:            pmdarima: 2.0.4
2024-11-11 09:38:59,661:INFO:              psutil: 6.1.0
2024-11-11 09:38:59,661:INFO:          markupsafe: 3.0.2
2024-11-11 09:38:59,661:INFO:             pickle5: Not installed
2024-11-11 09:38:59,661:INFO:         cloudpickle: 3.1.0
2024-11-11 09:38:59,661:INFO:         deprecation: 2.1.0
2024-11-11 09:38:59,661:INFO:              xxhash: 3.5.0
2024-11-11 09:38:59,661:INFO:           wurlitzer: 3.1.1
2024-11-11 09:38:59,661:INFO:PyCaret optional dependencies:
2024-11-11 09:38:59,677:INFO:                shap: Not installed
2024-11-11 09:38:59,677:INFO:           interpret: Not installed
2024-11-11 09:38:59,677:INFO:                umap: Not installed
2024-11-11 09:38:59,677:INFO:     ydata_profiling: Not installed
2024-11-11 09:38:59,677:INFO:  explainerdashboard: Not installed
2024-11-11 09:38:59,677:INFO:             autoviz: Not installed
2024-11-11 09:38:59,677:INFO:           fairlearn: Not installed
2024-11-11 09:38:59,677:INFO:          deepchecks: Not installed
2024-11-11 09:38:59,677:INFO:             xgboost: Not installed
2024-11-11 09:38:59,677:INFO:            catboost: Not installed
2024-11-11 09:38:59,677:INFO:              kmodes: Not installed
2024-11-11 09:38:59,677:INFO:             mlxtend: Not installed
2024-11-11 09:38:59,677:INFO:       statsforecast: Not installed
2024-11-11 09:38:59,677:INFO:        tune_sklearn: Not installed
2024-11-11 09:38:59,677:INFO:                 ray: Not installed
2024-11-11 09:38:59,677:INFO:            hyperopt: Not installed
2024-11-11 09:38:59,677:INFO:              optuna: Not installed
2024-11-11 09:38:59,677:INFO:               skopt: Not installed
2024-11-11 09:38:59,677:INFO:              mlflow: Not installed
2024-11-11 09:38:59,677:INFO:              gradio: Not installed
2024-11-11 09:38:59,677:INFO:             fastapi: Not installed
2024-11-11 09:38:59,677:INFO:             uvicorn: Not installed
2024-11-11 09:38:59,677:INFO:              m2cgen: Not installed
2024-11-11 09:38:59,677:INFO:           evidently: Not installed
2024-11-11 09:38:59,677:INFO:               fugue: Not installed
2024-11-11 09:38:59,677:INFO:           streamlit: Not installed
2024-11-11 09:38:59,677:INFO:             prophet: Not installed
2024-11-11 09:38:59,677:INFO:None
2024-11-11 09:38:59,677:INFO:Set up data.
2024-11-11 09:38:59,723:INFO:Set up folding strategy.
2024-11-11 09:38:59,723:INFO:Set up train/test split.
2024-11-11 09:38:59,772:INFO:Set up index.
2024-11-11 09:38:59,772:INFO:Assigning column types.
2024-11-11 09:38:59,783:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-11 09:38:59,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-11 09:38:59,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:38:59,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:38:59,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:38:59,924:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-11 09:38:59,925:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:38:59,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:38:59,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:38:59,944:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-11 09:38:59,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:38:59,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:38:59,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:39:00,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,053:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-11 09:39:00,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,162:INFO:Preparing preprocessing pipeline...
2024-11-11 09:39:00,163:INFO:Set up simple imputation.
2024-11-11 09:39:00,165:INFO:Set up encoding of categorical features.
2024-11-11 09:39:00,166:INFO:Set up column name cleaning.
2024-11-11 09:39:00,289:INFO:Finished creating preprocessing pipeline.
2024-11-11 09:39:00,294:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sexo', 'Agotamiento Emo.'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somat...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo',
                                                                    'SA45'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-11 09:39:00,294:INFO:Creating final display dataframe.
2024-11-11 09:39:00,606:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 13)
4        Transformed data shape         (372, 33)
5   Transformed train set shape         (260, 33)
6    Transformed test set shape         (112, 33)
7              Numeric features                 2
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                 4
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1923
2024-11-11 09:39:00,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:00,738:INFO:setup() successfully completed in 1.28s...............
2024-11-11 09:39:15,645:INFO:PyCaret ClassificationExperiment
2024-11-11 09:39:15,645:INFO:Logging name: clf-default-name
2024-11-11 09:39:15,645:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-11 09:39:15,645:INFO:version 3.3.2
2024-11-11 09:39:15,645:INFO:Initializing setup()
2024-11-11 09:39:15,646:INFO:self.USI: c136
2024-11-11 09:39:15,646:INFO:self._variable_keys: {'_ml_usecase', 'X', 'fold_shuffle_param', '_available_plots', 'X_train', 'y_train', 'seed', 'target_param', 'memory', 'n_jobs_param', 'USI', 'exp_id', 'exp_name_log', 'pipeline', 'gpu_param', 'data', 'logging_param', 'fix_imbalance', 'gpu_n_jobs_param', 'X_test', 'idx', 'y', 'html_param', 'log_plots_param', 'fold_groups_param', 'fold_generator', 'y_test', 'is_multiclass'}
2024-11-11 09:39:15,646:INFO:Checking environment
2024-11-11 09:39:15,646:INFO:python_version: 3.11.2
2024-11-11 09:39:15,646:INFO:python_build: ('main', 'Aug 26 2024 07:20:54')
2024-11-11 09:39:15,646:INFO:machine: x86_64
2024-11-11 09:39:15,646:INFO:platform: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-11 09:39:15,646:INFO:Memory: svmem(total=16721203200, available=10080407552, percent=39.7, used=6152003584, free=5714841600, active=1480302592, inactive=8488849408, buffers=496410624, cached=4357947392, shared=139919360, slab=543256576)
2024-11-11 09:39:15,647:INFO:Physical Core: 4
2024-11-11 09:39:15,647:INFO:Logical Core: 8
2024-11-11 09:39:15,647:INFO:Checking libraries
2024-11-11 09:39:15,647:INFO:System:
2024-11-11 09:39:15,647:INFO:    python: 3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]
2024-11-11 09:39:15,647:INFO:executable: /home/kurt/coding/TesisPycaret/backend/.venv/bin/python
2024-11-11 09:39:15,647:INFO:   machine: Linux-6.1.0-26-amd64-x86_64-with-glibc2.36
2024-11-11 09:39:15,647:INFO:PyCaret required dependencies:
2024-11-11 09:39:15,647:INFO:                 pip: 23.0.1
2024-11-11 09:39:15,647:INFO:          setuptools: 66.1.1
2024-11-11 09:39:15,647:INFO:             pycaret: 3.3.2
2024-11-11 09:39:15,647:INFO:             IPython: 8.29.0
2024-11-11 09:39:15,647:INFO:          ipywidgets: 8.1.5
2024-11-11 09:39:15,647:INFO:                tqdm: 4.66.6
2024-11-11 09:39:15,647:INFO:               numpy: 1.26.4
2024-11-11 09:39:15,647:INFO:              pandas: 2.1.4
2024-11-11 09:39:15,647:INFO:              jinja2: 3.1.4
2024-11-11 09:39:15,647:INFO:               scipy: 1.11.4
2024-11-11 09:39:15,647:INFO:              joblib: 1.3.2
2024-11-11 09:39:15,647:INFO:             sklearn: 1.4.2
2024-11-11 09:39:15,647:INFO:                pyod: 2.0.2
2024-11-11 09:39:15,647:INFO:            imblearn: 0.12.4
2024-11-11 09:39:15,647:INFO:   category_encoders: 2.6.4
2024-11-11 09:39:15,647:INFO:            lightgbm: 4.5.0
2024-11-11 09:39:15,647:INFO:               numba: 0.60.0
2024-11-11 09:39:15,647:INFO:            requests: 2.32.3
2024-11-11 09:39:15,647:INFO:          matplotlib: 3.7.5
2024-11-11 09:39:15,647:INFO:          scikitplot: 0.3.7
2024-11-11 09:39:15,647:INFO:         yellowbrick: 1.5
2024-11-11 09:39:15,647:INFO:              plotly: 5.24.1
2024-11-11 09:39:15,647:INFO:    plotly-resampler: Not installed
2024-11-11 09:39:15,647:INFO:             kaleido: 0.2.1
2024-11-11 09:39:15,647:INFO:           schemdraw: 0.15
2024-11-11 09:39:15,647:INFO:         statsmodels: 0.14.4
2024-11-11 09:39:15,647:INFO:              sktime: 0.26.0
2024-11-11 09:39:15,648:INFO:               tbats: 1.1.3
2024-11-11 09:39:15,648:INFO:            pmdarima: 2.0.4
2024-11-11 09:39:15,648:INFO:              psutil: 6.1.0
2024-11-11 09:39:15,648:INFO:          markupsafe: 3.0.2
2024-11-11 09:39:15,648:INFO:             pickle5: Not installed
2024-11-11 09:39:15,648:INFO:         cloudpickle: 3.1.0
2024-11-11 09:39:15,648:INFO:         deprecation: 2.1.0
2024-11-11 09:39:15,648:INFO:              xxhash: 3.5.0
2024-11-11 09:39:15,648:INFO:           wurlitzer: 3.1.1
2024-11-11 09:39:15,648:INFO:PyCaret optional dependencies:
2024-11-11 09:39:15,648:INFO:                shap: Not installed
2024-11-11 09:39:15,648:INFO:           interpret: Not installed
2024-11-11 09:39:15,648:INFO:                umap: Not installed
2024-11-11 09:39:15,648:INFO:     ydata_profiling: Not installed
2024-11-11 09:39:15,648:INFO:  explainerdashboard: Not installed
2024-11-11 09:39:15,648:INFO:             autoviz: Not installed
2024-11-11 09:39:15,648:INFO:           fairlearn: Not installed
2024-11-11 09:39:15,648:INFO:          deepchecks: Not installed
2024-11-11 09:39:15,648:INFO:             xgboost: Not installed
2024-11-11 09:39:15,648:INFO:            catboost: Not installed
2024-11-11 09:39:15,648:INFO:              kmodes: Not installed
2024-11-11 09:39:15,648:INFO:             mlxtend: Not installed
2024-11-11 09:39:15,648:INFO:       statsforecast: Not installed
2024-11-11 09:39:15,648:INFO:        tune_sklearn: Not installed
2024-11-11 09:39:15,648:INFO:                 ray: Not installed
2024-11-11 09:39:15,648:INFO:            hyperopt: Not installed
2024-11-11 09:39:15,648:INFO:              optuna: Not installed
2024-11-11 09:39:15,648:INFO:               skopt: Not installed
2024-11-11 09:39:15,648:INFO:              mlflow: Not installed
2024-11-11 09:39:15,648:INFO:              gradio: Not installed
2024-11-11 09:39:15,648:INFO:             fastapi: Not installed
2024-11-11 09:39:15,648:INFO:             uvicorn: Not installed
2024-11-11 09:39:15,648:INFO:              m2cgen: Not installed
2024-11-11 09:39:15,648:INFO:           evidently: Not installed
2024-11-11 09:39:15,648:INFO:               fugue: Not installed
2024-11-11 09:39:15,649:INFO:           streamlit: Not installed
2024-11-11 09:39:15,649:INFO:             prophet: Not installed
2024-11-11 09:39:15,649:INFO:None
2024-11-11 09:39:15,649:INFO:Set up data.
2024-11-11 09:39:15,657:INFO:Set up folding strategy.
2024-11-11 09:39:15,657:INFO:Set up train/test split.
2024-11-11 09:39:15,663:INFO:Set up index.
2024-11-11 09:39:15,663:INFO:Assigning column types.
2024-11-11 09:39:15,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-11 09:39:15,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,818:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-11 09:39:15,855:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-11 09:39:15,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,929:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-11 09:39:15,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:15,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,039:INFO:Preparing preprocessing pipeline...
2024-11-11 09:39:16,040:INFO:Set up simple imputation.
2024-11-11 09:39:16,042:INFO:Set up encoding of categorical features.
2024-11-11 09:39:16,042:INFO:Set up column name cleaning.
2024-11-11 09:39:16,165:INFO:Finished creating preprocessing pipeline.
2024-11-11 09:39:16,171:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sexo', 'Agotamiento Emo.'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somat...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo',
                                                                    'SA45'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-11-11 09:39:16,171:INFO:Creating final display dataframe.
2024-11-11 09:39:16,451:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target       Agotamiento
2                   Target type        Multiclass
3           Original data shape         (372, 13)
4        Transformed data shape         (372, 33)
5   Transformed train set shape         (260, 33)
6    Transformed test set shape         (112, 33)
7              Numeric features                 2
8          Categorical features                10
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              c136
2024-11-11 09:39:16,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-11 09:39:16,591:INFO:setup() successfully completed in 0.95s...............
2024-11-11 09:39:19,689:INFO:Initializing compare_models()
2024-11-11 09:39:19,689:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-11-11 09:39:19,690:INFO:Checking exceptions
2024-11-11 09:39:19,699:INFO:Preparing display monitor
2024-11-11 09:39:19,728:INFO:Initializing Logistic Regression
2024-11-11 09:39:19,728:INFO:Total runtime is 5.4478645324707035e-06 minutes
2024-11-11 09:39:19,732:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:19,733:INFO:Initializing create_model()
2024-11-11 09:39:19,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=lr, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:19,733:INFO:Checking exceptions
2024-11-11 09:39:19,733:INFO:Importing libraries
2024-11-11 09:39:19,733:INFO:Copying training dataset
2024-11-11 09:39:19,740:INFO:Defining folds
2024-11-11 09:39:19,740:INFO:Declaring metric variables
2024-11-11 09:39:19,746:INFO:Importing untrained model
2024-11-11 09:39:19,751:INFO:Logistic Regression Imported successfully
2024-11-11 09:39:19,760:INFO:Starting cross validation
2024-11-11 09:39:19,763:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:21,718:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:21,718:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:21,730:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:21,739:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:21,759:INFO:Calculating mean and std
2024-11-11 09:39:21,762:INFO:Creating metrics dataframe
2024-11-11 09:39:21,768:INFO:Uploading results into container
2024-11-11 09:39:21,769:INFO:Uploading model into container now
2024-11-11 09:39:21,770:INFO:_master_model_container: 1
2024-11-11 09:39:21,770:INFO:_display_container: 2
2024-11-11 09:39:21,771:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-11 09:39:21,771:INFO:create_model() successfully completed......................................
2024-11-11 09:39:21,957:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:21,958:INFO:Creating metrics dataframe
2024-11-11 09:39:21,963:INFO:Initializing K Neighbors Classifier
2024-11-11 09:39:21,964:INFO:Total runtime is 0.037268853187561034 minutes
2024-11-11 09:39:21,967:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:21,968:INFO:Initializing create_model()
2024-11-11 09:39:21,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=knn, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:21,968:INFO:Checking exceptions
2024-11-11 09:39:21,968:INFO:Importing libraries
2024-11-11 09:39:21,968:INFO:Copying training dataset
2024-11-11 09:39:21,973:INFO:Defining folds
2024-11-11 09:39:21,974:INFO:Declaring metric variables
2024-11-11 09:39:21,977:INFO:Importing untrained model
2024-11-11 09:39:21,980:INFO:K Neighbors Classifier Imported successfully
2024-11-11 09:39:21,986:INFO:Starting cross validation
2024-11-11 09:39:21,989:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:23,642:INFO:Calculating mean and std
2024-11-11 09:39:23,643:INFO:Creating metrics dataframe
2024-11-11 09:39:23,646:INFO:Uploading results into container
2024-11-11 09:39:23,647:INFO:Uploading model into container now
2024-11-11 09:39:23,647:INFO:_master_model_container: 2
2024-11-11 09:39:23,648:INFO:_display_container: 2
2024-11-11 09:39:23,648:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-11 09:39:23,648:INFO:create_model() successfully completed......................................
2024-11-11 09:39:23,773:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:23,773:INFO:Creating metrics dataframe
2024-11-11 09:39:23,779:INFO:Initializing Naive Bayes
2024-11-11 09:39:23,779:INFO:Total runtime is 0.0675286054611206 minutes
2024-11-11 09:39:23,783:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:23,783:INFO:Initializing create_model()
2024-11-11 09:39:23,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=nb, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:23,783:INFO:Checking exceptions
2024-11-11 09:39:23,783:INFO:Importing libraries
2024-11-11 09:39:23,784:INFO:Copying training dataset
2024-11-11 09:39:23,788:INFO:Defining folds
2024-11-11 09:39:23,788:INFO:Declaring metric variables
2024-11-11 09:39:23,791:INFO:Importing untrained model
2024-11-11 09:39:23,794:INFO:Naive Bayes Imported successfully
2024-11-11 09:39:23,802:INFO:Starting cross validation
2024-11-11 09:39:23,806:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:24,035:INFO:Calculating mean and std
2024-11-11 09:39:24,036:INFO:Creating metrics dataframe
2024-11-11 09:39:24,038:INFO:Uploading results into container
2024-11-11 09:39:24,038:INFO:Uploading model into container now
2024-11-11 09:39:24,038:INFO:_master_model_container: 3
2024-11-11 09:39:24,038:INFO:_display_container: 2
2024-11-11 09:39:24,039:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-11 09:39:24,039:INFO:create_model() successfully completed......................................
2024-11-11 09:39:24,146:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:24,146:INFO:Creating metrics dataframe
2024-11-11 09:39:24,152:INFO:Initializing Decision Tree Classifier
2024-11-11 09:39:24,153:INFO:Total runtime is 0.07375047604242961 minutes
2024-11-11 09:39:24,155:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:24,156:INFO:Initializing create_model()
2024-11-11 09:39:24,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=dt, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:24,156:INFO:Checking exceptions
2024-11-11 09:39:24,156:INFO:Importing libraries
2024-11-11 09:39:24,156:INFO:Copying training dataset
2024-11-11 09:39:24,160:INFO:Defining folds
2024-11-11 09:39:24,160:INFO:Declaring metric variables
2024-11-11 09:39:24,165:INFO:Importing untrained model
2024-11-11 09:39:24,168:INFO:Decision Tree Classifier Imported successfully
2024-11-11 09:39:24,174:INFO:Starting cross validation
2024-11-11 09:39:24,178:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:24,369:INFO:Calculating mean and std
2024-11-11 09:39:24,370:INFO:Creating metrics dataframe
2024-11-11 09:39:24,371:INFO:Uploading results into container
2024-11-11 09:39:24,372:INFO:Uploading model into container now
2024-11-11 09:39:24,372:INFO:_master_model_container: 4
2024-11-11 09:39:24,373:INFO:_display_container: 2
2024-11-11 09:39:24,373:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-11 09:39:24,373:INFO:create_model() successfully completed......................................
2024-11-11 09:39:24,466:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:24,466:INFO:Creating metrics dataframe
2024-11-11 09:39:24,472:INFO:Initializing SVM - Linear Kernel
2024-11-11 09:39:24,472:INFO:Total runtime is 0.07906928857167562 minutes
2024-11-11 09:39:24,474:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:24,474:INFO:Initializing create_model()
2024-11-11 09:39:24,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=svm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:24,475:INFO:Checking exceptions
2024-11-11 09:39:24,475:INFO:Importing libraries
2024-11-11 09:39:24,475:INFO:Copying training dataset
2024-11-11 09:39:24,479:INFO:Defining folds
2024-11-11 09:39:24,479:INFO:Declaring metric variables
2024-11-11 09:39:24,482:INFO:Importing untrained model
2024-11-11 09:39:24,485:INFO:SVM - Linear Kernel Imported successfully
2024-11-11 09:39:24,491:INFO:Starting cross validation
2024-11-11 09:39:24,494:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:24,676:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:24,681:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:24,690:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:24,694:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:24,713:INFO:Calculating mean and std
2024-11-11 09:39:24,714:INFO:Creating metrics dataframe
2024-11-11 09:39:24,716:INFO:Uploading results into container
2024-11-11 09:39:24,717:INFO:Uploading model into container now
2024-11-11 09:39:24,717:INFO:_master_model_container: 5
2024-11-11 09:39:24,718:INFO:_display_container: 2
2024-11-11 09:39:24,718:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-11 09:39:24,718:INFO:create_model() successfully completed......................................
2024-11-11 09:39:24,813:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:24,813:INFO:Creating metrics dataframe
2024-11-11 09:39:24,819:INFO:Initializing Ridge Classifier
2024-11-11 09:39:24,819:INFO:Total runtime is 0.08486342827479046 minutes
2024-11-11 09:39:24,822:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:24,822:INFO:Initializing create_model()
2024-11-11 09:39:24,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=ridge, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:24,822:INFO:Checking exceptions
2024-11-11 09:39:24,822:INFO:Importing libraries
2024-11-11 09:39:24,822:INFO:Copying training dataset
2024-11-11 09:39:24,826:INFO:Defining folds
2024-11-11 09:39:24,826:INFO:Declaring metric variables
2024-11-11 09:39:24,829:INFO:Importing untrained model
2024-11-11 09:39:24,834:INFO:Ridge Classifier Imported successfully
2024-11-11 09:39:24,842:INFO:Starting cross validation
2024-11-11 09:39:24,846:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:25,140:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:25,140:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:25,141:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:25,142:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:25,156:INFO:Calculating mean and std
2024-11-11 09:39:25,157:INFO:Creating metrics dataframe
2024-11-11 09:39:25,158:INFO:Uploading results into container
2024-11-11 09:39:25,159:INFO:Uploading model into container now
2024-11-11 09:39:25,159:INFO:_master_model_container: 6
2024-11-11 09:39:25,159:INFO:_display_container: 2
2024-11-11 09:39:25,159:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-11 09:39:25,159:INFO:create_model() successfully completed......................................
2024-11-11 09:39:25,256:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:25,256:INFO:Creating metrics dataframe
2024-11-11 09:39:25,263:INFO:Initializing Random Forest Classifier
2024-11-11 09:39:25,263:INFO:Total runtime is 0.09225129286448162 minutes
2024-11-11 09:39:25,265:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:25,266:INFO:Initializing create_model()
2024-11-11 09:39:25,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=rf, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:25,266:INFO:Checking exceptions
2024-11-11 09:39:25,266:INFO:Importing libraries
2024-11-11 09:39:25,266:INFO:Copying training dataset
2024-11-11 09:39:25,270:INFO:Defining folds
2024-11-11 09:39:25,270:INFO:Declaring metric variables
2024-11-11 09:39:25,273:INFO:Importing untrained model
2024-11-11 09:39:25,276:INFO:Random Forest Classifier Imported successfully
2024-11-11 09:39:25,282:INFO:Starting cross validation
2024-11-11 09:39:25,285:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:25,715:INFO:Calculating mean and std
2024-11-11 09:39:25,718:INFO:Creating metrics dataframe
2024-11-11 09:39:25,724:INFO:Uploading results into container
2024-11-11 09:39:25,725:INFO:Uploading model into container now
2024-11-11 09:39:25,726:INFO:_master_model_container: 7
2024-11-11 09:39:25,726:INFO:_display_container: 2
2024-11-11 09:39:25,727:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-11 09:39:25,727:INFO:create_model() successfully completed......................................
2024-11-11 09:39:25,879:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:25,879:INFO:Creating metrics dataframe
2024-11-11 09:39:25,885:INFO:Initializing Quadratic Discriminant Analysis
2024-11-11 09:39:25,885:INFO:Total runtime is 0.10261947711308798 minutes
2024-11-11 09:39:25,887:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:25,888:INFO:Initializing create_model()
2024-11-11 09:39:25,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=qda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:25,888:INFO:Checking exceptions
2024-11-11 09:39:25,888:INFO:Importing libraries
2024-11-11 09:39:25,888:INFO:Copying training dataset
2024-11-11 09:39:25,892:INFO:Defining folds
2024-11-11 09:39:25,892:INFO:Declaring metric variables
2024-11-11 09:39:25,895:INFO:Importing untrained model
2024-11-11 09:39:25,898:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-11 09:39:25,904:INFO:Starting cross validation
2024-11-11 09:39:25,907:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:26,103:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-11 09:39:26,103:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-11 09:39:26,103:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-11 09:39:26,103:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-11 09:39:26,164:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,167:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,168:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,168:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,186:INFO:Calculating mean and std
2024-11-11 09:39:26,188:INFO:Creating metrics dataframe
2024-11-11 09:39:26,191:INFO:Uploading results into container
2024-11-11 09:39:26,191:INFO:Uploading model into container now
2024-11-11 09:39:26,192:INFO:_master_model_container: 8
2024-11-11 09:39:26,192:INFO:_display_container: 2
2024-11-11 09:39:26,192:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-11 09:39:26,192:INFO:create_model() successfully completed......................................
2024-11-11 09:39:26,296:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:26,296:INFO:Creating metrics dataframe
2024-11-11 09:39:26,303:INFO:Initializing Ada Boost Classifier
2024-11-11 09:39:26,303:INFO:Total runtime is 0.10959359010060629 minutes
2024-11-11 09:39:26,306:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:26,307:INFO:Initializing create_model()
2024-11-11 09:39:26,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=ada, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:26,307:INFO:Checking exceptions
2024-11-11 09:39:26,307:INFO:Importing libraries
2024-11-11 09:39:26,307:INFO:Copying training dataset
2024-11-11 09:39:26,312:INFO:Defining folds
2024-11-11 09:39:26,312:INFO:Declaring metric variables
2024-11-11 09:39:26,316:INFO:Importing untrained model
2024-11-11 09:39:26,320:INFO:Ada Boost Classifier Imported successfully
2024-11-11 09:39:26,327:INFO:Starting cross validation
2024-11-11 09:39:26,331:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:26,460:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-11 09:39:26,460:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-11 09:39:26,473:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-11 09:39:26,475:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-11 09:39:26,562:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,566:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,592:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,602:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:26,611:INFO:Calculating mean and std
2024-11-11 09:39:26,612:INFO:Creating metrics dataframe
2024-11-11 09:39:26,614:INFO:Uploading results into container
2024-11-11 09:39:26,614:INFO:Uploading model into container now
2024-11-11 09:39:26,614:INFO:_master_model_container: 9
2024-11-11 09:39:26,614:INFO:_display_container: 2
2024-11-11 09:39:26,615:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-11 09:39:26,615:INFO:create_model() successfully completed......................................
2024-11-11 09:39:26,709:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:26,709:INFO:Creating metrics dataframe
2024-11-11 09:39:26,718:INFO:Initializing Gradient Boosting Classifier
2024-11-11 09:39:26,718:INFO:Total runtime is 0.11650394201278687 minutes
2024-11-11 09:39:26,722:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:26,722:INFO:Initializing create_model()
2024-11-11 09:39:26,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=gbc, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:26,723:INFO:Checking exceptions
2024-11-11 09:39:26,723:INFO:Importing libraries
2024-11-11 09:39:26,723:INFO:Copying training dataset
2024-11-11 09:39:26,727:INFO:Defining folds
2024-11-11 09:39:26,727:INFO:Declaring metric variables
2024-11-11 09:39:26,731:INFO:Importing untrained model
2024-11-11 09:39:26,735:INFO:Gradient Boosting Classifier Imported successfully
2024-11-11 09:39:26,740:INFO:Starting cross validation
2024-11-11 09:39:26,743:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:27,098:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,098:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,098:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,099:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,114:INFO:Calculating mean and std
2024-11-11 09:39:27,115:INFO:Creating metrics dataframe
2024-11-11 09:39:27,117:INFO:Uploading results into container
2024-11-11 09:39:27,117:INFO:Uploading model into container now
2024-11-11 09:39:27,118:INFO:_master_model_container: 10
2024-11-11 09:39:27,118:INFO:_display_container: 2
2024-11-11 09:39:27,118:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-11 09:39:27,118:INFO:create_model() successfully completed......................................
2024-11-11 09:39:27,212:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:27,212:INFO:Creating metrics dataframe
2024-11-11 09:39:27,220:INFO:Initializing Linear Discriminant Analysis
2024-11-11 09:39:27,220:INFO:Total runtime is 0.12488001187642415 minutes
2024-11-11 09:39:27,223:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:27,224:INFO:Initializing create_model()
2024-11-11 09:39:27,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=lda, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:27,224:INFO:Checking exceptions
2024-11-11 09:39:27,224:INFO:Importing libraries
2024-11-11 09:39:27,224:INFO:Copying training dataset
2024-11-11 09:39:27,229:INFO:Defining folds
2024-11-11 09:39:27,229:INFO:Declaring metric variables
2024-11-11 09:39:27,232:INFO:Importing untrained model
2024-11-11 09:39:27,235:INFO:Linear Discriminant Analysis Imported successfully
2024-11-11 09:39:27,240:INFO:Starting cross validation
2024-11-11 09:39:27,243:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:27,414:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,415:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,415:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,415:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-11-11 09:39:27,432:INFO:Calculating mean and std
2024-11-11 09:39:27,433:INFO:Creating metrics dataframe
2024-11-11 09:39:27,434:INFO:Uploading results into container
2024-11-11 09:39:27,434:INFO:Uploading model into container now
2024-11-11 09:39:27,435:INFO:_master_model_container: 11
2024-11-11 09:39:27,435:INFO:_display_container: 2
2024-11-11 09:39:27,435:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-11 09:39:27,435:INFO:create_model() successfully completed......................................
2024-11-11 09:39:27,528:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:27,528:INFO:Creating metrics dataframe
2024-11-11 09:39:27,536:INFO:Initializing Extra Trees Classifier
2024-11-11 09:39:27,536:INFO:Total runtime is 0.13014344374338785 minutes
2024-11-11 09:39:27,540:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:27,540:INFO:Initializing create_model()
2024-11-11 09:39:27,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=et, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:27,540:INFO:Checking exceptions
2024-11-11 09:39:27,540:INFO:Importing libraries
2024-11-11 09:39:27,541:INFO:Copying training dataset
2024-11-11 09:39:27,545:INFO:Defining folds
2024-11-11 09:39:27,545:INFO:Declaring metric variables
2024-11-11 09:39:27,548:INFO:Importing untrained model
2024-11-11 09:39:27,551:INFO:Extra Trees Classifier Imported successfully
2024-11-11 09:39:27,558:INFO:Starting cross validation
2024-11-11 09:39:27,561:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:39:27,986:INFO:Calculating mean and std
2024-11-11 09:39:27,987:INFO:Creating metrics dataframe
2024-11-11 09:39:27,988:INFO:Uploading results into container
2024-11-11 09:39:27,989:INFO:Uploading model into container now
2024-11-11 09:39:27,989:INFO:_master_model_container: 12
2024-11-11 09:39:27,989:INFO:_display_container: 2
2024-11-11 09:39:27,989:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-11 09:39:27,990:INFO:create_model() successfully completed......................................
2024-11-11 09:39:28,092:INFO:SubProcess create_model() end ==================================
2024-11-11 09:39:28,092:INFO:Creating metrics dataframe
2024-11-11 09:39:28,101:INFO:Initializing Light Gradient Boosting Machine
2024-11-11 09:39:28,101:INFO:Total runtime is 0.13956421216328938 minutes
2024-11-11 09:39:28,104:INFO:SubProcess create_model() called ==================================
2024-11-11 09:39:28,104:INFO:Initializing create_model()
2024-11-11 09:39:28,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=lightgbm, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:39:28,105:INFO:Checking exceptions
2024-11-11 09:39:28,105:INFO:Importing libraries
2024-11-11 09:39:28,105:INFO:Copying training dataset
2024-11-11 09:39:28,109:INFO:Defining folds
2024-11-11 09:39:28,109:INFO:Declaring metric variables
2024-11-11 09:39:28,112:INFO:Importing untrained model
2024-11-11 09:39:28,117:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-11 09:39:28,123:INFO:Starting cross validation
2024-11-11 09:39:28,126:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:42:57,070:INFO:Calculating mean and std
2024-11-11 09:42:57,071:INFO:Creating metrics dataframe
2024-11-11 09:42:57,073:INFO:Uploading results into container
2024-11-11 09:42:57,073:INFO:Uploading model into container now
2024-11-11 09:42:57,073:INFO:_master_model_container: 13
2024-11-11 09:42:57,073:INFO:_display_container: 2
2024-11-11 09:42:57,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-11 09:42:57,074:INFO:create_model() successfully completed......................................
2024-11-11 09:42:57,177:INFO:SubProcess create_model() end ==================================
2024-11-11 09:42:57,177:INFO:Creating metrics dataframe
2024-11-11 09:42:57,186:INFO:Initializing Dummy Classifier
2024-11-11 09:42:57,186:INFO:Total runtime is 3.624306511878967 minutes
2024-11-11 09:42:57,188:INFO:SubProcess create_model() called ==================================
2024-11-11 09:42:57,189:INFO:Initializing create_model()
2024-11-11 09:42:57,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=dummy, fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f89f5da48d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:42:57,189:INFO:Checking exceptions
2024-11-11 09:42:57,189:INFO:Importing libraries
2024-11-11 09:42:57,189:INFO:Copying training dataset
2024-11-11 09:42:57,194:INFO:Defining folds
2024-11-11 09:42:57,194:INFO:Declaring metric variables
2024-11-11 09:42:57,196:INFO:Importing untrained model
2024-11-11 09:42:57,199:INFO:Dummy Classifier Imported successfully
2024-11-11 09:42:57,204:INFO:Starting cross validation
2024-11-11 09:42:57,207:INFO:Cross validating with StratifiedKFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2024-11-11 09:42:57,401:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-11 09:42:57,401:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-11 09:42:57,421:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-11 09:42:57,424:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-11 09:42:57,434:INFO:Calculating mean and std
2024-11-11 09:42:57,435:INFO:Creating metrics dataframe
2024-11-11 09:42:57,437:INFO:Uploading results into container
2024-11-11 09:42:57,437:INFO:Uploading model into container now
2024-11-11 09:42:57,438:INFO:_master_model_container: 14
2024-11-11 09:42:57,438:INFO:_display_container: 2
2024-11-11 09:42:57,438:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-11 09:42:57,438:INFO:create_model() successfully completed......................................
2024-11-11 09:42:57,550:INFO:SubProcess create_model() end ==================================
2024-11-11 09:42:57,550:INFO:Creating metrics dataframe
2024-11-11 09:42:57,566:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-11-11 09:42:57,574:INFO:Initializing create_model()
2024-11-11 09:42:57,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-11 09:42:57,574:INFO:Checking exceptions
2024-11-11 09:42:57,577:INFO:Importing libraries
2024-11-11 09:42:57,577:INFO:Copying training dataset
2024-11-11 09:42:57,582:INFO:Defining folds
2024-11-11 09:42:57,582:INFO:Declaring metric variables
2024-11-11 09:42:57,583:INFO:Importing untrained model
2024-11-11 09:42:57,583:INFO:Declaring custom model
2024-11-11 09:42:57,583:INFO:Decision Tree Classifier Imported successfully
2024-11-11 09:42:57,586:INFO:Cross validation set to False
2024-11-11 09:42:57,586:INFO:Fitting Model
2024-11-11 09:42:57,699:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-11 09:42:57,700:INFO:create_model() successfully completed......................................
2024-11-11 09:42:57,829:INFO:_master_model_container: 14
2024-11-11 09:42:57,830:INFO:_display_container: 2
2024-11-11 09:42:57,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-11 09:42:57,830:INFO:compare_models() successfully completed......................................
2024-11-11 09:43:48,529:INFO:Initializing plot_model()
2024-11-11 09:43:48,529:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f89f68d2350>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2024-11-11 09:43:48,529:INFO:Checking exceptions
2024-11-11 09:43:48,542:INFO:Preloading libraries
2024-11-11 09:43:48,542:INFO:Copying training dataset
2024-11-11 09:43:48,543:INFO:Plot type: confusion_matrix
2024-11-11 09:43:48,922:INFO:Fitting Model
2024-11-11 09:43:48,927:WARNING:/home/kurt/coding/TesisPycaret/backend/.venv/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-11-11 09:43:48,928:INFO:Scoring test/hold-out set
2024-11-11 09:43:49,218:INFO:Visual Rendered Successfully
2024-11-11 09:43:49,316:INFO:plot_model() successfully completed......................................
2024-11-11 10:25:24,964:INFO:Initializing save_model()
2024-11-11 10:25:24,964:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), model_name=modelo-SA45-ECE_Sexo_SA45-total, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sexo', 'Agotamiento Emo.'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somat...
                                                                    'Depresión',
                                                                    'Ansiedad',
                                                                    'Hostilidad',
                                                                    'Ans. '
                                                                    'Fóbica',
                                                                    'Ideación '
                                                                    'Paran.',
                                                                    'Psicoticismo',
                                                                    'SA45'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-11-11 10:25:24,964:INFO:Adding model into prep_pipe
2024-11-11 10:25:24,985:INFO:modelo-SA45-ECE_Sexo_SA45-total.pkl saved in current working directory
2024-11-11 10:25:24,990:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Sexo', 'Agotamiento Emo.'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Somatización', 'O...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, random_state=123,
                                        splitter='best'))],
         verbose=False)
2024-11-11 10:25:24,991:INFO:save_model() successfully completed......................................
